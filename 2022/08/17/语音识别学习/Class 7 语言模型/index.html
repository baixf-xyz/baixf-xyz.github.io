

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head><!-- hexo injector head_begin start -->
<link rel="stylesheet" href="/css/custom-theme.css">
<link rel="stylesheet" href="/css/animation.css">
<!-- hexo injector head_begin end -->
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/pi.jpg">
  <link rel="icon" href="/img/pi.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="白小飞">
  <meta name="keywords" content="">
  
    <meta name="description" content="声学模型(AM)与语言模型(LM)">
<meta property="og:type" content="article">
<meta property="og:title" content="Class 7 语言模型">
<meta property="og:url" content="https://blog.baixf.shop/2022/08/17/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%AD%A6%E4%B9%A0/Class%207%20%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="白小飞のblog">
<meta property="og:description" content="声学模型(AM)与语言模型(LM)">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog屏幕截图 2022-06-25 213320.jpg">
<meta property="article:published_time" content="2022-08-17T00:24:11.000Z">
<meta property="article:modified_time" content="2025-05-15T05:17:25.801Z">
<meta property="article:author" content="白小飞">
<meta property="article:tag" content="语音识别">
<meta property="article:tag" content="ASR">
<meta property="article:tag" content="RNN">
<meta property="article:tag" content="LM">
<meta property="article:tag" content="平滑算法">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog屏幕截图 2022-06-25 213320.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
    <meta name="referrer" content="no-referrer" />
  
  <title>Class 7 语言模型 - 白小飞のblog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.baixf.shop","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":"32cfe221d23ea3ac2ca847f1e865c570","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":21061303,"cnzz":1279684341,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?32cfe221d23ea3ac2ca847f1e865c570";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  

  

  

  
    <!-- 51.la Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript('//js.users.51.la/21061303.js');
      }
    </script>
  

  
    <!-- cnzz Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript('//s4.cnzz.com/z_stat.php?id=1279684341&show=pic');
      }
    </script>
  

  



  <style>ins.adsbygoogle[data-ad-status="unfilled"] { display: none !important; }</style>
<!-- hexo injector head_end start -->
<script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/global.js"></script>
<script src="/js/cat/custom-utils.js"></script>
<script src="/js/cat/onClick.js"></script>
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>白小飞のBlog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog屏幕截图 2022-06-25 213133.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Class 7 语言模型"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-08-17 00:24" pubdate>
          2022年8月17日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5.8k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          49 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
<aside class="sidebar d-none d-xl-block" style="margin-right:-1rem;z-index:-1"><ins class="adsbygoogle" style="display:flex;justify-content:center;min-width:160px;max-width:300px;width:100%;height:600px;position:sticky;top:2rem" data-ad-client="ca-pub-8876055955767828" data-ad-slot="9285507003"></ins><script> (adsbygoogle = window.adsbygoogle || []).push({}); </script></aside>
    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Class 7 语言模型</h1>
            
            
              <div class="markdown-body">
                
                <p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208161621616.png" srcset="/img/loading.gif" lazyload alt="image-20220816161808832"></p>
<h4 id="整体流程图"><a href="#整体流程图" class="headerlink" title="整体流程图"></a>整体流程图</h4><p>为什么要加入语音模型？本质：一种约束，约束合理性。</p>
<blockquote>
<p>对于连续语音识别，可能有上万个词，解码过程是复杂的，识别结果组合很多，只使用声学模型是不够的，需要引入语言模型来约束识别结果。</p>
</blockquote>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208161624128.png" srcset="/img/loading.gif" lazyload alt="image-20220816162434019"></p>
<h3 id="一、统计语言模型"><a href="#一、统计语言模型" class="headerlink" title="一、统计语言模型"></a>一、统计语言模型</h3><blockquote>
<p>孤立词识别不需要考虑上下文关系和指令是基于规则的不需要考虑上下文，但LVCSR( large vocabulary continuous speech recognition,大词汇量连续语识别 )类似于自然下人与人的对话，不可能找到其中的规则，所以有了统计语言模型。</p>
</blockquote>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208161632528.png" srcset="/img/loading.gif" lazyload alt="image-20220816163232496"></p>
<p>简言之：统计语言模型是所有词序列上的一个概率分布。</p>
<p>问：统计语言模型有什么用？<br>1.它可以给我们任意词序列的概率，即帮助我们确定哪个词序列可能性大。<br>2.给定一个词序列，可以预测下一个最可能出现的词语! [用于ASR，MT等]</p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208161648606.png" srcset="/img/loading.gif" lazyload alt="image-20220816164801567"></p>
<p>如何获得语言模型中的概率？在语料库中计数。</p>
<ul>
<li><p>训练集(training-set)与测试集(test-set)</p>
</li>
<li><p>保留集(held-out set): 从训练集中分离，用来计算一些其它参数，如插值模型中的插值系数。</p>
</li>
<li><p>语言模型中一些常见术语：</p>
<p><strong>I uh gave a re-report yesterday</strong></p>
<p><strong>我是不是老了</strong></p>
<ul>
<li>有声停顿(fillers&#x2F;filled pauses): 如uh就是一个没有实际意义的有声停顿。</li>
<li>截断(fragment):表示没有说完整，如re-。</li>
<li>词目(lemma)：词语主干(stem)相同，比如dogs和dog是一个词目。</li>
<li>词形(wordforms)：完整的词语样子，比如dogs和dog是两个词形。</li>
<li>型(type):语料库或者字典中不同单词的数目。</li>
<li>例(token):语料中单词数目。(数数)</li>
<li>字典(vocabulary)：语言模型的基本组件，规定了我对那些元素进行统计。</li>
</ul>
</li>
</ul>
<h3 id="二、N-gram语言模型与评价方法"><a href="#二、N-gram语言模型与评价方法" class="headerlink" title="二、N-gram语言模型与评价方法"></a>二、N-gram语言模型与评价方法</h3><p>举个栗子：It is too expensive to buy</p>
<p>$$<br>P(\text { buy } \mid \text { It is too expensive to })&#x3D;\frac{C(\text { It is too expensive to buy })}{C(\text { It is too expensive to })}<br>$$<br>问题：当历史信息越长，越难在预料库中找到完全一致的序列。</p>
<p>引入马尔科夫假设：随意一个词出现的概率只与前面出现的有限的n-1个词有关，则可以用最近的几个历史词代替整个历史词串，从而近似。</p>
<p><strong>N-gram</strong>：用前N-1个词作为历史，估计当前第N个词。</p>
<p>$$<br>\mathrm{P}\left(\mathrm{w}<em>{\mathrm{i}} \mid \mathrm{w}</em>{\mathrm{i}}^{\mathrm{i}-1}\right)&#x3D;\mathrm{P}\left(\mathrm{w}<em>{\mathrm{i}} \mid \mathrm{w}</em>{\mathrm{i}-\mathrm{N}+1}^{\mathrm{i}-1}\right)<br>$$<br>如2-gram(bigram): </p>
<p>$$<br>\mathrm{P}\left(\mathrm{w}<em>{\mathrm{i}} \mid \mathrm{w}</em>{\mathrm{i}}^{\mathrm{i}-1}\right)&#x3D;\mathrm{P}\left(\mathrm{w}<em>{\mathrm{i}} \mid \mathrm{w}</em>{\mathrm{i}-1}\right)<br>$$<br>如何估计N-gram? 使用最大似然方法，就是在训练预料上进行数数。</p>
<p>$$<br>\begin{aligned}<br>&amp;\mathrm{P}\left(\mathrm{w}<em>{\mathrm{i}} \mid \mathrm{w}</em>{\mathrm{i}-\mathrm{N}+1}^{\mathrm{i}-1}\right)&#x3D;\frac{\mathrm{C}\left(\mathrm{w}<em>{\mathrm{i}-\mathrm{N}+1}^{\mathrm{i}-1} \mathrm{w}</em>{\mathrm{i}}\right)}{\mathrm{C}\left(\mathrm{w}<em>{\mathrm{i}-\mathrm{N}+1}^{\mathrm{i}-1}\right)}\<br>&amp;\mathrm{P}\left(\mathrm{w}</em>{\mathrm{i}} \mid \mathrm{w}<em>{\mathrm{i}-1}\right)&#x3D;\frac{\mathrm{C}\left(\mathrm{w}</em>{\mathrm{i}-1} \mathrm{w}<em>{\mathrm{i}}\right)}{\mathrm{C}\left(\mathrm{w}</em>{\mathrm{i}-1}\right)}<br>\end{aligned}<br>$$</p>
<blockquote>
<p>开头结尾如何处理？未知词？</p>
<p>习惯上，ASR 领域用<s>和 &lt;&#x2F; s &gt;来标记开头结尾，并方便统计。<br>没有在vocabulary中的词(OOV, out of vocabulary)，一般标记为&lt; UNK &gt;。</p>
</blockquote>
<p><strong>评估方法</strong>：1. 根据应用实地测试，2. 困惑度（Perplexity）</p>
<p>在测试集W &#x3D;w1,w2,…,w_N，困惑度就是用单词数归一化后的测试集概率：</p>
<p>$$<br>\begin{aligned}<br>\mathrm{PP}(\mathrm{W}) &amp;&#x3D;\mathrm{P}\left(\mathrm{w}<em>{1} \mathrm{w}</em>{2} \ldots \mathrm{w}<em>{\mathrm{N}}\right)^{-\frac{1}{N}} \<br>&amp;&#x3D;\sqrt{\frac{1}{\mathrm{P}\left(\mathrm{w}</em>{1} \mathrm{w}<em>{2} \ldots \mathrm{w}</em>{\mathrm{N}}\right)}} \<br>&amp;&#x3D;\sqrt{\prod_{\mathrm{i}&#x3D;1}^{\mathrm{N}} \frac{1}{\mathrm{P}\left(\mathrm{w}<em>{\mathrm{i}} \mid \mathrm{w}</em>{\mathrm{i}-\mathrm{N}+1}^{\mathrm{i}-1}\right)}}<br>\end{aligned}<br>$$<br>句子越好，概率越大，困惑度越小，也就是模型对句子越不困惑。求出来的困惑度值相当于一个虚拟词典大小，下一个词就从这个虚拟词典中选。值越大选择就越多，选对就越困难，说明语言模型训练的就越差；值越小选择就越少，选对的可能性就越大，说明语言模型训练的越好。<br>在工具包里:</p>
<ul>
<li>PPL：考虑词数和句子数(i.e. 考虑&lt; &#x2F;s&gt;)</li>
<li>PPL1：只考虑词数</li>
</ul>
<h3 id="三、平滑算法-Smoothing"><a href="#三、平滑算法-Smoothing" class="headerlink" title="三、平滑算法(Smoothing)"></a>三、平滑算法(Smoothing)</h3><blockquote>
<p>由于语料的稀疏性，有些词序列找不到，那么它的概率是0，在测试的时候就不能正确识别这个词序列。为了解决这个问题，提出了平滑算法。</p>
<p>本质：将一部分看见的事件概率量分给未看见的事件。</p>
</blockquote>
<h4 id="拉普拉斯平滑（Laplace-Smoothing-x2F-Add-one-Smoothing"><a href="#拉普拉斯平滑（Laplace-Smoothing-x2F-Add-one-Smoothing" class="headerlink" title="拉普拉斯平滑（Laplace Smoothing&#x2F;Add-one Smoothing)"></a>拉普拉斯平滑（Laplace Smoothing&#x2F;Add-one Smoothing)</h4><p>Intuition：将每个计数都加一，从而使得任何词序列都有计数。</p>
<p>这样的话就可以把本来概率为0的结果变成一个很小的值，为了保证所有实例的概率总和为1，将分母增加实例的种类数V，也就是词典大小。</p>
<blockquote>
<p>token: 语料中单词数目（数数）</p>
</blockquote>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208161802320.png" srcset="/img/loading.gif" lazyload alt="image-20220816180233283"></p>
<p>两个重要的概念：</p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162138534.png" srcset="/img/loading.gif" lazyload alt="image-20220816213802479"></p>
<p>Laplace Smoothing缺点：原来计数量较高的词序列，概率削减严重。</p>
<p>–&gt; Add-delta smoothing (缓解)</p>
<h4 id="古德图灵平滑-Good-turing-Smoothing"><a href="#古德图灵平滑-Good-turing-Smoothing" class="headerlink" title="古德图灵平滑(Good-turing Smoothing)"></a>古德图灵平滑(Good-turing Smoothing)</h4><blockquote>
<p>齐夫(Zipf)定律：语言中大部分词都是低频词，只有很少的常用词。</p>
<p>自然语言语料库中，一个词出现的频率与它在频率表里面的排名成反比。</p>
</blockquote>
<p>在实际中很少单独使用，和其他平滑算法一起使用。</p>
<p>Intuition: 用你看见过一次的事件估计为看见的事件，并以此类推用看见两次的事件估计看见一次的事件…</p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162158285.png" srcset="/img/loading.gif" lazyload alt="image-20220816215852223"></p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162208032.png" srcset="/img/loading.gif" lazyload alt="image-20220816220814998"></p>
<p>问题：显然，如果一个词在语料中出现了5000次的词序列(e.g. the)，但是没有出现5001次的词序列。难道这个概率变为0？</p>
<blockquote>
<p>方法一本质平滑拟合得到位置的那个情况；</p>
<p>方法二本质是大于一定值则认为不打折处理了。</p>
</blockquote>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162159513.png" srcset="/img/loading.gif" lazyload alt="image-20220816215953474"></p>
<h4 id="插值-Interpolation-平滑"><a href="#插值-Interpolation-平滑" class="headerlink" title="插值(Interpolation)平滑"></a>插值(Interpolation)平滑</h4><p>Intuition：从所有N-grams估计中，把所有的概率估计混合。例如，我们优化一个tri-gram模型，我们将统计的tri-gram，bigram和unigram计数进行插值。</p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162215312.png" srcset="/img/loading.gif" lazyload alt="image-20220816221547269"></p>
<p>如何确定系数？在held-out set上使用MLE的方法</p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162303642.png" srcset="/img/loading.gif" lazyload alt="image-20220816230257541"></p>
<h4 id="Bucketing方法扩展Interpolation"><a href="#Bucketing方法扩展Interpolation" class="headerlink" title="Bucketing方法扩展Interpolation"></a>Bucketing方法扩展Interpolation</h4><p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162306556.png" srcset="/img/loading.gif" lazyload alt="image-20220816230643511"></p>
<h4 id="回退-Back-off-平滑"><a href="#回退-Back-off-平滑" class="headerlink" title="回退(Back off)平滑"></a>回退(Back off)平滑</h4><p>Intuition：如果有非零的高阶语言模型，我们直接只用。只有当高级语言模型存在计数零时，我们回退到低阶语言模型。(递归)</p>
<h4 id="卡茨平滑-Katz-Smoothing-—递归回退算法"><a href="#卡茨平滑-Katz-Smoothing-—递归回退算法" class="headerlink" title="卡茨平滑(Katz Smoothing)—递归回退算法"></a>卡茨平滑(Katz Smoothing)—递归回退算法</h4><p>Intuition：若N阶语言模型存在，直接使用打折后的概率(常使用Good-turing算法进行打折)；若高阶语言模型不存在(i.e. unseen events)，将打折节省出的概率量，依照N-1阶的语言模型概率进行分配，依此类推。</p>
<p>卡茨平滑(Katz Smoothing)—归一化系数怎么求？</p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162321370.png" srcset="/img/loading.gif" lazyload alt="image-20220816232153327"></p>
<h4 id="克奈瑟-内平滑-Kneser-Ney-Smoothing"><a href="#克奈瑟-内平滑-Kneser-Ney-Smoothing" class="headerlink" title="克奈瑟-内平滑(Kneser-Ney Smoothing)"></a>克奈瑟-内平滑(Kneser-Ney Smoothing)</h4><p>Intuition：对于一个词，如果它在语料库中出现更多种不同上下文(context)时，它可能应该有更高的概率。</p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162328625.png" srcset="/img/loading.gif" lazyload alt="image-20220816232832577"></p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162328487.png" srcset="/img/loading.gif" lazyload alt="image-20220816232859448"></p>
<h3 id="四、语言模型的存储格式—APRA-Format-及工具包"><a href="#四、语言模型的存储格式—APRA-Format-及工具包" class="headerlink" title="四、语言模型的存储格式—APRA Format 及工具包"></a>四、语言模型的存储格式—APRA Format 及工具包</h3><p>ARPA是N-gram的标准存储格式，是一个ASCII文件，小标题后边跟着一个列表，列举出所有非零的N元语法概率。每个N元语法条目中以此为：折扣后对数概率（log10格式），词序列，回退权重（log10格式）。</p>
<p>$$<br>\text { e.g.: } \log <em>{10}\left(\mathrm{w}</em>{\mathrm{i}} \mid \mathrm{w}<em>{\mathrm{i}-1}\right) \mathrm{w}</em>{\mathrm{i}-1} \mathrm{w}<em>{\mathrm{i}} \log <em>{10} \alpha\left(\mathrm{w}</em>{\mathrm{i}-1} \mathrm{w}</em>{\mathrm{i}}\right)<br>$$<br><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162330443.png" srcset="/img/loading.gif" lazyload alt="image-20220816233034398"></p>
<blockquote>
<p>思考题：</p>
<p>1.最高阶语法和 &lt; &#x2F; s &gt; 结尾的任意阶语法没有回退权重。</p>
<p>2.插值模型和回退模型都可以如此储存。</p>
</blockquote>
<h4 id="工具包"><a href="#工具包" class="headerlink" title="工具包"></a>工具包</h4><ul>
<li>SRILM(最常用):<br><a target="_blank" rel="noopener" href="http://www.speech.sri.com/projects/srilm">http://www.speech.sri.com/projects/srilm</a></li>
<li>KenLM:<br><a target="_blank" rel="noopener" href="https://github.com/kpu/kenlm">https://github.com/kpu/kenlm</a></li>
<li>KaldiLM:<br><a target="_blank" rel="noopener" href="http://www.danielpovey.com/files/kaldi/kaldi_lm.tar.gz">http://www.danielpovey.com/files/kaldi/kaldi_lm.tar.gz</a></li>
<li>IRSTLM:<a target="_blank" rel="noopener" href="https://github.com/irstlm-team/">https://github.com/irstlm-team/</a></li>
</ul>
<h4 id="从代码和应用ARPA的角度思考"><a href="#从代码和应用ARPA的角度思考" class="headerlink" title="从代码和应用ARPA的角度思考"></a>从代码和应用ARPA的角度思考</h4><p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162341719.png" srcset="/img/loading.gif" lazyload alt="image-20220816234145673"></p>
<h3 id="五、RNN语言模型"><a href="#五、RNN语言模型" class="headerlink" title="五、RNN语言模型"></a>五、RNN语言模型</h3><p>统计语言模型的目标：如果可能它希望依赖所有历史推测当前。</p>
<p>$$<br>\begin{aligned}<br>P(S) &amp;&#x3D;P\left(x_{1}&#x3D;w_{1}, \ldots x_{n}&#x3D;w_{n}\right)&#x3D;P\left(w_{1}^{n}\right) \<br>&amp;&#x3D;P\left(w_{1}\right) P\left(w_{2} \mid w_{1}\right) P\left(w_{3} \mid w_{1}^{2}\right) \ldots P\left(w_{n} \mid w_{1}^{n-1}\right) \<br>&amp;&#x3D;\prod_{k&#x3D;1}^{n} P\left(w_{k} \mid w_{1}^{k-1}\right)<br>\end{aligned}<br>$$<br>Recurrent Neural Network正好满足这个要求。</p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162347077.png" srcset="/img/loading.gif" lazyload alt="image-20220816234731036"></p>
<p>Input: vocabulary size one-hot vector</p>
<p>Structure: Simple Recurrent Neural Network<br>(extend: LSTM, GRU and so on)</p>
<p>Output: vocabulary size vector with softmax(extend: Top N(e.g. 2k) high frequency words + 1 low frequency word bag)</p>
<p>优化：低频词袋法</p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208162348886.png" srcset="/img/loading.gif" lazyload alt="image-20220816234814806"></p>
<h3 id="六、其它语言模型思想简介"><a href="#六、其它语言模型思想简介" class="headerlink" title="六、其它语言模型思想简介"></a>六、其它语言模型思想简介</h3><h4 id="基于类的N元语言模型-Class-based-x2F-Clustering-N-gram"><a href="#基于类的N元语言模型-Class-based-x2F-Clustering-N-gram" class="headerlink" title="基于类的N元语言模型(Class-based&#x2F;Clustering N-gram)"></a>基于类的N元语言模型(Class-based&#x2F;Clustering N-gram)</h4><p>Intuition:在语言学中，将具有同样语义的字词归为一类是一种常见的解决数据稀疏的方法。受此启发，在语言模型中，根据词性分析，语义分析，或者特定任务时人为设计，我们可以将词和类别建立联系，通过类别信息，帮助我们提升语言模型建模性能。（e.g.航空订票系统）</p>
<h4 id="缓存模型-Cache-Model"><a href="#缓存模型-Cache-Model" class="headerlink" title="缓存模型(Cache Model)"></a>缓存模型(Cache Model)</h4><p>Intuition: 如果一个词在句子中用到，那么它很可能被再次用到。<br>例如：两个人在讨论旅游，它们可能反复用到同一个地名。</p>
<h3 id="七、大词汇量连续语音识别梳理"><a href="#七、大词汇量连续语音识别梳理" class="headerlink" title="七、大词汇量连续语音识别梳理"></a>七、大词汇量连续语音识别梳理</h3><ul>
<li>语言模型：建模word间的跳转概率。</li>
<li>字典(vocabulary)：提供word到phone的映射，及语言模型建模元素。</li>
<li>HMM：建模phone或triphone等基本单元发声过程。</li>
<li>GMM：建模每个HMM状态的发射概率，即声学似然分。</li>
<li>决策树：triphone等建模单元绑定(共享pdf)，解决数据稀疏问题。</li>
<li>前向后向算法：更新HMM参数。（软对齐）</li>
<li>EM算法：更新GMM参数。</li>
<li>Viterbi算法：解码或对齐。</li>
<li>EmbeddingTraining算法：更新GMM-HMM模型参数，即ViterbiTraining。（硬对齐）</li>
<li>特征提取：从音频获取MFCC，PLP，Fbank等特征。</li>
<li>DNN：建模每帧观测的后验概率，后转化为似然概率，提供给每个HMM状态。</li>
</ul>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/202208170005859.png" srcset="/img/loading.gif" lazyload alt="image-20220817000515812"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_39529413/article/details/117604864">n-gram语言模型LM</a>
<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://blog.csdn.net/lm709409753/article/details/90290901">语言模型-Ngram</a>
<a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32292060">一起入门语言模型(Language Models)</a>
<a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28080127">深入浅出讲解语言模型</a>
<a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:5" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/35833334/answer/67944671">语音识别中，声学模型与语言模型扮演什么角色？或者说是怎么通过两个模型进行语音识别的?</a>
<a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:6" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/274765693/answer/376705811">语音识别声学模型、解码器、语言模型的作用分别是什么？</a>
<a href="#fnref:6" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%AD%A6%E4%B9%A0/" class="category-chain-item">学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/" class="category-chain-item">语音识别</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/">#语音识别</a>
      
        <a href="/tags/ASR/">#ASR</a>
      
        <a href="/tags/RNN/">#RNN</a>
      
        <a href="/tags/LM/">#LM</a>
      
        <a href="/tags/%E5%B9%B3%E6%BB%91%E7%AE%97%E6%B3%95/">#平滑算法</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Class 7 语言模型</div>
      <div>https://blog.baixf.shop/2022/08/17/语音识别学习/Class 7 语言模型/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>白小飞</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年8月17日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>

<div style="width:100%;display:flex;justify-content:center;margin-bottom:1.5rem"><ins class="adsbygoogle" style="display:flex;justify-content:center;max-width:845px;width:100%;height:90px" data-ad-client="ca-pub-8876055955767828" data-ad-slot="9285507003"></ins><script> (adsbygoogle = window.adsbygoogle || []).push({}); </script></div>

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/08/20/Data%20Structure/Q2-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="Q2-数据结构">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Q2-数据结构</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/08/08/Data%20Structure/code-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="code-数据结构">
                        <span class="hidden-mobile">code-数据结构</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <div> <span id="timeDate">载入天数...</span> <span id="times">载入时分秒...</span> <script src="/js/duration.js"></script> </div> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
    <!-- cnzz Analytics Icon -->
    <span id="cnzz_stat_icon_1279684341" style="display: none"></span>
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  
<script src="/js/click.js"></script>
<script src="/js/bg.js"></script>
<script src="/js/forbid.js"></script>
<script src="/js/cloudflare.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8876055955767828" crossorigin="anonymous"></script>

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
