

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head><!-- hexo injector head_begin start -->
<link rel="stylesheet" href="/css/custom-theme.css">
<link rel="stylesheet" href="/css/animation.css">
<!-- hexo injector head_begin end -->
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/pi.jpg">
  <link rel="icon" href="/img/pi.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="白小飞">
  <meta name="keywords" content="">
  
    <meta name="description" content="Kaldi thchs30手札~">
<meta property="og:type" content="article">
<meta property="og:title" content="Class6 作业-Kaldi的thchs30实例">
<meta property="og:url" content="https://blog.baixf.shop/2022/08/31/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%AD%A6%E4%B9%A0/Class6%20%E4%BD%9C%E4%B8%9A-Kaldi%E7%9A%84thchs30%E5%AE%9E%E4%BE%8B/index.html">
<meta property="og:site_name" content="白小飞のblog">
<meta property="og:description" content="Kaldi thchs30手札~">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220915152556525.png">
<meta property="article:published_time" content="2022-08-31T23:59:11.000Z">
<meta property="article:modified_time" content="2025-05-15T05:17:25.801Z">
<meta property="article:author" content="白小飞">
<meta property="article:tag" content="语音识别">
<meta property="article:tag" content="ASR">
<meta property="article:tag" content="kaldi">
<meta property="article:tag" content="单音素">
<meta property="article:tag" content="三音素">
<meta property="article:tag" content="状态绑定">
<meta property="article:tag" content="thchs30">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220915152556525.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
    <meta name="referrer" content="no-referrer" />
  
  <title>Class6 作业-Kaldi的thchs30实例 - 白小飞のblog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.baixf.shop","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":"32cfe221d23ea3ac2ca847f1e865c570","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":21061303,"cnzz":1279684341,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?32cfe221d23ea3ac2ca847f1e865c570";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  

  

  

  
    <!-- 51.la Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript('//js.users.51.la/21061303.js');
      }
    </script>
  

  
    <!-- cnzz Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript('//s4.cnzz.com/z_stat.php?id=1279684341&show=pic');
      }
    </script>
  

  



  <style>ins.adsbygoogle[data-ad-status="unfilled"] { display: none !important; }</style>
<!-- hexo injector head_end start -->
<script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/global.js"></script>
<script src="/js/cat/custom-utils.js"></script>
<script src="/js/cat/onClick.js"></script>
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>白小飞のBlog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220901092503075.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Class6 作业-Kaldi的thchs30实例"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-08-31 23:59" pubdate>
          2022年8月31日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          85k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          713 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
<aside class="sidebar d-none d-xl-block" style="margin-right:-1rem;z-index:-1"><ins class="adsbygoogle" style="display:flex;justify-content:center;min-width:160px;max-width:300px;width:100%;height:600px;position:sticky;top:2rem" data-ad-client="ca-pub-8876055955767828" data-ad-slot="9285507003"></ins><script> (adsbygoogle = window.adsbygoogle || []).push({}); </script></aside>
    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Class6 作业-Kaldi的thchs30实例</h1>
            
            
              <div class="markdown-body">
                
                <p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/c6b51e811fb8ed947bf024653e505a25.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>在处理数据之前，我们要知道thchs30数据集包含三部分：train（训练集）、dev（开发集）和test（测试集）。其中dev的作用是在某些步骤与train进行交叉验证的，如<code>local/nnet/run_dnn.sh</code>同时用到<code>exp/tri4b_ali</code>和<code>exp/tri4b_ali_cv</code>。训练和测试的目标数据也分为两类：word（词）和phone（音素）。</p>
<ol>
<li><p><code>local/thchs-30_data_prep.sh</code>主要工作是从<code>$thchs/data_thchs30</code>（下载的数据）三部分分别生成<code>word.txt（词序列），phone.txt（音素序列），text（与word.txt相同），wav.scp（语音），utt2pk（句子与说话人的映射），spk2utt（说话人与句子的映射）</code></p>
</li>
<li><p><code>#produce MFCC features</code>是提取MFCC特征，分为两步，先通过<code>steps/make_mfcc.sh</code>提取MFCC特征，再通过<code>steps/compute_cmvn_stats.sh</code>计算倒谱均值和方差归一化。</p>
</li>
<li><p><code>#prepare language stuff</code>是构建一个包含训练和解码用到的词的词典。而语言模型已经由王东老师处理好了，如果不打算改语言模型，这段代码也不需要修改。</p>
</li>
</ol>
<ul>
<li>基于词的语言模型包含48k基于三元词的词，从gigaword语料库中随机选择文本信息进行训练得到，训练文本包含772000个句子，总计1800万词，1.15亿汉字<ul>
<li>基于音素的语言模型包含218个基于三元音的中文声调，从只有200万字的样本训练得到，之所以选择这么小的样本是因为在模型中尽可能少地保留语言信息，可以使得到的性能更直接地反映声学模型的质量。</li>
</ul>
</li>
<li>这两个语言模型都是由SRILM工具训练得到。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1512.01882v1.pdf">文献1</a>介绍了thchs30示例的主要流程。</p>
<ul>
<li>首先用标准的13维MFCC加上一阶和二阶导数训练单音素GMM系统，采用倒谱均值归一化（CMN）来降低通道效应。然后基于具有由LDA和MLLT变换的特征的单音系统构造三音GMM系统，最后的GMM系统用于为随后的DNN训练生成状态对齐。</li>
<li>基于GMM系统提供的对齐来训练DNN系统，特征是40维FBank，并且相邻的帧由11帧窗口（每侧5个窗口）连接。连接的特征被LDA转换，其中维度降低到200。然后应用全局均值和方差归一化以获得DNN输入。DNN架构由4个隐藏层组成，每个层由1200个单元组成，输出层由3386个单元组成。 基线DNN模型用交叉熵的标准训练。 使用随机梯度下降（SGD）算法来执行优化。 将迷你批量大小设定为256，初始学习率设定为0.008。</li>
<li>被噪声干扰的语音可以使用基于深度自动编码器（DAE）的噪声消除方法。DAE是自动编码器（AE）的一种特殊实现，通过在模型训练中对输入特征引入随机破坏。已经表明，该模型学习低维度特征的能力非常强大，并且可以用于恢复被噪声破坏的信号。在实践中，DAE被用作前端管道的特定组件。输入是11维Fbank特征（在均值归一化之后），输出是对应于中心帧的噪声消除特征。然后对输出进行LDA变换，提取全局标准化的常规Fbank特征，然后送到DNN声学模型（用纯净语音进行训练）。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/usr/bin/env bash</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">run.sh ：整体流程控制脚本，主入口脚本</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">Steps| Utils| tools：kaldi 脚本工具</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">cmd.sh：运行配置目录，并行执行命令，通常分 run.pl, queue.pl 两种</span><br>. ./cmd.sh ## You&#x27;ll want to change cmd.sh to something that will work on your system.<br>           ## This relates to the queue.<br><span class="hljs-meta prompt_">#</span><span class="language-bash">path.sh：环境变量相关脚本（kaldi公用的全局PATH变量的设置）</span><br>. ./path.sh<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">kaldi的源码的根目录，告诉程序kaldi在哪里</span><br>H=`pwd`  #exp home<br>n=8      #parallel jobs<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">corpus and trans directory</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">要训练的thchs30数据的目录</span><br>thchs=/home/baixf/kaldi/egs/thchs30/s5/thchs30-openslr<br></code></pre></td></tr></table></figure>

<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220901082632837.png" srcset="/img/loading.gif" lazyload alt="image-20220901082632837"></p>
<h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">step1:数据准备</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">you can obtain the database by uncommting the following lines</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">[ -d <span class="hljs-variable">$thchs</span> ] || <span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$thchs</span>  || <span class="hljs-built_in">exit</span> 1</span><br>echo &quot;downloading THCHS30 at $thchs ...&quot;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">download_and_untar.sh 功能：下载数据。</span><br>local/download_and_untar.sh $thchs  http://www.openslr.org/resources/18 data_thchs30  || exit 1<br>local/download_and_untar.sh $thchs  http://www.openslr.org/resources/18 resource      || exit 1<br>local/download_and_untar.sh $thchs  http://www.openslr.org/resources/18 test-noise    || exit 1<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">thchs-30_data_prep.sh 功能：进入thchs30-openslr/data_thchs30/train、dev、<span class="hljs-built_in">test</span>目录，它读取语料库并得到wav.scp和音标，生成文本text，wav.scp，uut3pk，spk2utt。</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">data preparation</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">generate text, wav.scp, utt2pk, spk2utt</span><br>local/thchs-30_data_prep.sh $H $thchs/data_thchs30 || exit 1;<br></code></pre></td></tr></table></figure>

<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220901082809708.png" srcset="/img/loading.gif" lazyload alt="image-20220901082809708"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">creating data/&#123;train,dev,test&#125;<br>cleaning data/train<br>preparing scps and text in data/train<br>cleaning data/dev<br>preparing scps and text in data/dev<br>cleaning data/test<br>preparing scps and text in data/test<br>creating test_phone for phone decoding<br></code></pre></td></tr></table></figure>

<p>Thchs30 经过初步处理后得到六种文本文件：wav.scp，每条语音的 ID 及其存储路径；text，每条语音的 ID 及其对应文本；utt2spk，每条语音的 ID 及其说话人 ID； spk2utt，每个说话人的 ID 及其所说语音的所有 ID；phone.txt，每条语音的 ID 及说话内容的声音标注；word.txt，每条语音的 ID 及其对应文本。</p>
<h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">step2:特征提取</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">produce MFCC features</span><br>rm -rf data/mfcc &amp;&amp; mkdir -p data/mfcc &amp;&amp;  cp -R data/&#123;train,dev,test,test_phone&#125; data/mfcc || exit 1;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">make_mfcc.sh 功能：MFCC特征提取。</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">其中n是make的cpu线程数目，train_cmd 是cmd.sh里的train_cmd变量，<span class="hljs-variable">$x</span>就是循环里的&#123;train,dev,<span class="hljs-built_in">test</span>&#125;了。</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">data/mfcc:输入数据目录；exp/make_mfcc:输出<span class="hljs-built_in">log</span>目录；mfcc:输出MFCC存放目录</span><br>for x in train dev test; do<br><span class="hljs-meta prompt_">   #</span><span class="language-bash">make  mfcc</span><br><span class="hljs-meta prompt_">   #</span><span class="language-bash">利用Kaldi的compute-mfcc-feats工具计算梅尔倒谱频率特征，然后利用copy-feats工具的参数—compress=<span class="hljs-literal">true</span> 压缩处理存储为两个文件类型ark和scp。</span><br>   steps/make_mfcc.sh --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/$x exp/make_mfcc/$x mfcc/$x || exit 1;<br>   <br><span class="hljs-meta prompt_">   #</span><span class="language-bash">compute cmvn</span><br><span class="hljs-meta prompt_">   #</span><span class="language-bash">计算cmvn倒谱均值方差归一化</span><br><span class="hljs-meta prompt_">   #</span><span class="language-bash">在实际情况下,受不同麦克风及音频通道的影响,会导致相同音素的特征差别比较大，通过CMVN可以得到均值为0，方差为1的标准特征。均值方差可以以一段语音为单位计算，但更好的是在一个较大的数据及上进行计算，这样识别效果会更加robustness。Kaldi中计算均值和方差的代码在compute-cmvn-stats.cc， 归一化在apply-cmvn.cc。</span><br><span class="hljs-meta prompt_">   #</span><span class="language-bash">这里还计算了倒谱均值方差归一化（Cepstral Mean and Variance Normalization，CMVN）系数用于声学特征的规整化，该方法旨在提高声学特征对说话人、录音设备、环境、音量等因素的鲁棒性。</span><br>   steps/compute_cmvn_stats.sh data/mfcc/$x exp/mfcc_cmvn/$x mfcc/$x || exit 1;<br>done<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">copy feats and cmvn to test.ph, avoid duplicated mfcc &amp; cmvn</span><br>cp data/mfcc/test/feats.scp data/mfcc/test_phone &amp;&amp; cp data/mfcc/test/cmvn.scp data/mfcc/test_phone || exit 1;<br></code></pre></td></tr></table></figure>

<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220916100950743.png" srcset="/img/loading.gif" lazyload alt="image-20220916100950743"></p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220916101056281.png" srcset="/img/loading.gif" lazyload alt="image-20220916101056281"></p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220916101001850.png" srcset="/img/loading.gif" lazyload alt="image-20220916101001850"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs shell">steps/make_mfcc.sh --nj 8 --cmd run.pl data/mfcc/train exp/make_mfcc/train mfcc/train<br>utils/validate_data_dir.sh: Successfully validated data-directory data/mfcc/train<br>steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>steps/make_mfcc.sh: Succeeded creating MFCC features for train<br>steps/compute_cmvn_stats.sh data/mfcc/train exp/mfcc_cmvn/train mfcc/train<br>Succeeded creating CMVN stats for train<br>steps/make_mfcc.sh --nj 8 --cmd run.pl data/mfcc/dev exp/make_mfcc/dev mfcc/dev<br>utils/validate_data_dir.sh: Successfully validated data-directory data/mfcc/dev<br>steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>steps/make_mfcc.sh: Succeeded creating MFCC features for dev<br>steps/compute_cmvn_stats.sh data/mfcc/dev exp/mfcc_cmvn/dev mfcc/dev<br>Succeeded creating CMVN stats for dev<br>steps/make_mfcc.sh --nj 8 --cmd run.pl data/mfcc/test exp/make_mfcc/test mfcc/test<br>utils/validate_data_dir.sh: Successfully validated data-directory data/mfcc/test<br>steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>steps/make_mfcc.sh: Succeeded creating MFCC features for test<br>steps/compute_cmvn_stats.sh data/mfcc/test exp/mfcc_cmvn/test mfcc/test<br>Succeeded creating CMVN stats for test<br></code></pre></td></tr></table></figure>

<h3 id="物料准备"><a href="#物料准备" class="headerlink" title="物料准备"></a>物料准备</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">step3:物料准备：准备发音词典L.fst和训练3-gram语言模型G.fst。</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">prepare language stuff</span> <br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">建立一个庞大的词汇库，包括单词的训练和解码</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">build a large lexicon that invovles words <span class="hljs-keyword">in</span> both the training and decoding.</span><br>(<br>  echo &quot;make word graph ...&quot; #制作词图<br>  <br>  cd $H; mkdir -p data/&#123;dict,lang,graph&#125; &amp;&amp; \ #在pwd下创建文件夹<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">将语音数据库目录的相应文件拷贝到dict目录？</span><br>  cp $thchs/resource/dict/&#123;extra_questions.txt,nonsilence_phones.txt,optional_silence.txt,silence_phones.txt&#125; data/dict &amp;&amp; \<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">将两个目录的lexicon.txt文件输出到data_thchs30/lm_word/lexicon.txt，同时过滤掉带&lt;s&gt;或&lt;/s&gt;的行，并且删除相同的重复信息</span><br>  cat $thchs/resource/dict/lexicon.txt $thchs/data_thchs30/lm_word/lexicon.txt | \<br>  grep -v &#x27;&lt;s&gt;&#x27; | grep -v &#x27;&lt;/s&gt;&#x27; | sort -u &gt; data/dict/lexicon.txt || exit 1;<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">调用utils下的prepare_lang.sh构建字典L.fst文件，来准备语言模型。即读取input的资源文件，生成data/lang目录，是Kaldi的标准语言文件夹。</span><br>  utils/prepare_lang.sh --position_dependent_phones false data/dict &quot;&lt;SPOKEN_NOISE&gt;&quot; data/local/lang data/lang || exit 1;<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">将word.3gram.lm压缩为word.3gram.lm.gz并保留文件</span><br>  gzip -c $thchs/data_thchs30/lm_word/word.3gram.lm &gt; data/graph/word.3gram.lm.gz || exit 1;<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">调用utils下的format_lm.sh来格式化语言模型，就是把arpa的language model 转换成 FST格式。</span><br><span class="hljs-meta prompt_">  #</span><span class="language-bash">format_lm.sh的主要目标就是根据语言模型生成G.fst文件。方便与之前的L.fst结合，发挥fst的优势。脚本最后会检测G.fst中是否存没有单词的空环，如果存在就会报错，这回这会导致后续HLG的determinization出现错误。其程序核心就是arpa2fst</span><br><span class="hljs-meta prompt_">  #</span><span class="language-bash">data/lang:输入，语言文件夹；data/graph/word.3gram.lm.gz:输入，ARPA格式的语言模型；<span class="hljs-variable">$thchs</span>/data_thchs30/lm_word/lexicon.txt：输入，词典；data/graph/lang：输出，G.fst语言模型</span><br>  utils/format_lm.sh data/lang data/graph/word.3gram.lm.gz $thchs/data_thchs30/lm_word/lexicon.txt data/graph/lang || exit 1;<br>)<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">make_phone_graph <span class="hljs-comment">#制作音素图</span></span><br>(<br>  echo &quot;make phone graph ...&quot;<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">在本目录下创建以下文件夹</span><br>  cd $H; mkdir -p data/&#123;dict_phone,graph_phone,lang_phone&#125; &amp;&amp; \<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">将语音数据库的目录的相应文件拷贝到dict目录？</span><br>  cp $thchs/resource/dict/&#123;extra_questions.txt,nonsilence_phones.txt,optional_silence.txt,silence_phones.txt&#125; data/dict_phone  &amp;&amp; \<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">将lexicon.txt文件输出到data/dict_phone/lexicon.txt，同时过滤掉带&lt;eps&gt;的行，并且删除相同的重复信息</span><br>  cat $thchs/data_thchs30/lm_phone/lexicon.txt | grep -v &#x27;&lt;eps&gt;&#x27; | sort -u &gt; data/dict_phone/lexicon.txt  &amp;&amp; \<br>  echo &quot;&lt;SPOKEN_NOISE&gt; sil &quot; &gt;&gt; data/dict_phone/lexicon.txt  || exit 1;<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">调用utils下的prepare_lang.sh构建字典L.fst文件，来准备语言模型。即读取input的资源文件，生成data/lang目录，是Kaldi的标准语言文件夹。</span><br>  utils/prepare_lang.sh --position_dependent_phones false data/dict_phone &quot;&lt;SPOKEN_NOISE&gt;&quot; data/local/lang_phone data/lang_phone || exit 1;<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">将phone.3gram.lm压缩为phone.3gram.lm.gz并保留文件</span><br>  gzip -c $thchs/data_thchs30/lm_phone/phone.3gram.lm &gt; data/graph_phone/phone.3gram.lm.gz  || exit 1;<br>  <br><span class="hljs-meta prompt_">  #</span><span class="language-bash">调用utils下的format_lm.sh来格式化语言模型，就是把arpa的language model 转换成 FST格式。</span><br><span class="hljs-meta prompt_">  #</span><span class="language-bash">data/lang_phone:输入，语言文件夹；data/graph_phone/word.3gram.lm.gz:输入，ARPA格式的语言模型；<span class="hljs-variable">$thchs</span>/data_thchs30/lm_phone/lexicon.txt：输入，词典；data/graph_phone/lang：输出，G.fst语言模型</span><br>  utils/format_lm.sh data/lang_phone data/graph_phone/phone.3gram.lm.gz $thchs/data_thchs30/lm_phone/lexicon.txt \<br>    data/graph_phone/lang  || exit 1;<br>)<br></code></pre></td></tr></table></figure>

<blockquote>
<p>ARPA是常用的语言模型存储格式, 由主要由两部分构成。模型文件头和模型文件体构成。</p>
</blockquote>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220901083336071.png" srcset="/img/loading.gif" lazyload alt="image-20220901083336071"></p>
<blockquote>
<p>在基于WFST框架的语音识别解码器静态构图中，使用WFST的Compose算法组合各个层次的信息，最终生成解码图HCLG， H&#x2F;C&#x2F;L&#x2F;G分别表示不同层级的FST，其中：</p>
<ul>
<li><p>H表示HMM层级的FST，输入为senone状态，输出为context-dependent phone。</p>
</li>
<li><p>C表示Context层级的FST，语音识别中的音素建模时考虑当前音素的上一个音素和下一个音素，C的输入为context-dependent phones，输出为phone。</p>
</li>
<li><p>L表示Lexicon层级的FST，对单个的词来讲，输入为该词的phone序列，输出为该词。</p>
</li>
<li><p>G表示Grammar层级的FST，一般Grammar用n-gram的语言模型表示，arpa的语言模型可以表示为等价的FST的形式，输入输出均为词。</p>
</li>
</ul>
<p>从H-&gt;C-&gt;L-&gt;G，低层次的FST的输出粒度刚好对应高一层次FST的输入粒度，通过Compose H<em>C</em>L*G(*表示Compose），即可将HMM&#x2F;Context&#x2F;Lexicon&#x2F;Grammar所有层次的信息构建在一个FST HCLG中，该HCLG输入为语音识别声学模型的建模单元senone，输出为词。</p>
<p>解码时，解码器直接使用已经构建好的HCLG，该HCLG已经全部展开，称之为<strong>静态图</strong>。</p>
</blockquote>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220901084427207.png" srcset="/img/loading.gif" lazyload alt="image-20220901084427207"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><code class="hljs shell">make word graph ...<br>utils/prepare_lang.sh --position_dependent_phones false data/dict &lt;SPOKEN_NOISE&gt; data/local/lang data/lang<br>Checking data/dict/silence_phones.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/dict/silence_phones.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/dict/silence_phones.txt is OK</span><br><br>Checking data/dict/optional_silence.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/dict/optional_silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/dict/optional_silence.txt is OK</span><br><br>Checking data/dict/nonsilence_phones.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/dict/nonsilence_phones.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/dict/nonsilence_phones.txt is OK</span><br><br>Checking disjoint: silence_phones.txt, nonsilence_phones.txt<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">disjoint property is OK.</span><br><br>Checking data/dict/lexicon.txt<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/dict/lexicon.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/dict/lexicon.txt is OK</span><br><br>Checking data/dict/extra_questions.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/dict/extra_questions.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/dict/extra_questions.txt is OK</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">SUCCESS [validating dictionary directory data/dict]</span><br><br>**Creating data/dict/lexiconp.txt from data/dict/lexicon.txt<br>fstaddselfloops data/lang/phones/wdisambig_phones.int data/lang/phones/wdisambig_words.int <br>prepare_lang.sh: validating output directory<br>utils/validate_lang.pl data/lang<br>Checking existence of separator file<br>separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.<br>Checking data/lang/phones.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones.txt is OK</span><br><br>Checking words.txt: #0 ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/words.txt is OK</span><br><br>Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">silence.txt and nonsilence.txt are disjoint</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">silence.txt and disambig.txt are disjoint</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">disambig.txt and nonsilence.txt are disjoint</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">disjoint property is OK</span><br><br>Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">found no unexplainable phones <span class="hljs-keyword">in</span> phones.txt</span><br><br>Checking data/lang/phones/context_indep.&#123;txt, int, csl&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">1 entry/entries <span class="hljs-keyword">in</span> data/lang/phones/context_indep.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/context_indep.&#123;txt, int, csl&#125; are OK</span><br><br>Checking data/lang/phones/nonsilence.&#123;txt, int, csl&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">217 entry/entries <span class="hljs-keyword">in</span> data/lang/phones/nonsilence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/nonsilence.&#123;txt, int, csl&#125; are OK</span><br><br>Checking data/lang/phones/silence.&#123;txt, int, csl&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">1 entry/entries <span class="hljs-keyword">in</span> data/lang/phones/silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/silence.&#123;txt, int, csl&#125; are OK</span><br><br>Checking data/lang/phones/optional_silence.&#123;txt, int, csl&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">1 entry/entries <span class="hljs-keyword">in</span> data/lang/phones/optional_silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/optional_silence.&#123;txt, int, csl&#125; are OK</span><br><br>Checking data/lang/phones/disambig.&#123;txt, int, csl&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">57 entry/entries <span class="hljs-keyword">in</span> data/lang/phones/disambig.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/disambig.&#123;txt, int, csl&#125; are OK</span><br><br>Checking data/lang/phones/roots.&#123;txt, int&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">218 entry/entries <span class="hljs-keyword">in</span> data/lang/phones/roots.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/roots.&#123;txt, int&#125; are OK</span><br><br>Checking data/lang/phones/sets.&#123;txt, int&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">218 entry/entries <span class="hljs-keyword">in</span> data/lang/phones/sets.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/sets.&#123;txt, int&#125; are OK</span><br><br>Checking data/lang/phones/extra_questions.&#123;txt, int&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">7 entry/entries <span class="hljs-keyword">in</span> data/lang/phones/extra_questions.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/extra_questions.&#123;txt, int&#125; are OK</span><br><br>Checking optional_silence.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/lang/phones/optional_silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/optional_silence.txt is OK</span><br><br>Checking disambiguation symbols: #0 and #1<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/disambig.txt has <span class="hljs-string">&quot;#0&quot;</span> and <span class="hljs-string">&quot;#1&quot;</span></span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/disambig.txt is OK</span><br><br>Checking topo ...<br><br>Checking word-level disambiguation symbols...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)</span><br>Checking data/lang/oov.&#123;txt, int&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">1 entry/entries <span class="hljs-keyword">in</span> data/lang/oov.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/oov.int corresponds to data/lang/oov.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/oov.&#123;txt, int&#125; are OK</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/L.fst is olabel sorted</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang/L_disambig.fst is olabel sorted</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">SUCCESS [validating lang directory data/lang]</span><br>Converting &#x27;data/graph/word.3gram.lm.gz&#x27; to FST<br>arpa2fst --disambig-symbol=#0 --read-symbol-table=data/graph/lang/words.txt - data/graph/lang/G.fst <br>LOG (arpa2fst[5.5.1050~1-0fb50]:Read():arpa-file-parser.cc:94) Reading \data\ section.<br>LOG (arpa2fst[5.5.1050~1-0fb50]:Read():arpa-file-parser.cc:149) Reading \1-grams: section.<br>LOG (arpa2fst[5.5.1050~1-0fb50]:Read():arpa-file-parser.cc:149) Reading \2-grams: section.<br>LOG (arpa2fst[5.5.1050~1-0fb50]:Read():arpa-file-parser.cc:149) Reading \3-grams: section.<br>LOG (arpa2fst[5.5.1050~1-0fb50]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 3076353 to 454251<br>fstisstochastic data/graph/lang/G.fst <br>-7.27093e-08 -0.832396<br>Succeeded in formatting LM: &#x27;data/graph/word.3gram.lm.gz&#x27;<br></code></pre></td></tr></table></figure>

<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220901084440685.png" srcset="/img/loading.gif" lazyload></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><code class="hljs shell">make phone graph ...<br>utils/prepare_lang.sh --position_dependent_phones false data/dict_phone &lt;SPOKEN_NOISE&gt; data/local/lang_phone data/lang_phone<br>Checking data/dict_phone/silence_phones.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/dict_phone/silence_phones.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/dict_phone/silence_phones.txt is OK</span><br><br>Checking data/dict_phone/optional_silence.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/dict_phone/optional_silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/dict_phone/optional_silence.txt is OK</span><br><br>Checking data/dict_phone/nonsilence_phones.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/dict_phone/nonsilence_phones.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/dict_phone/nonsilence_phones.txt is OK</span><br><br>Checking disjoint: silence_phones.txt, nonsilence_phones.txt<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">disjoint property is OK.</span><br><br>Checking data/dict_phone/lexicon.txt<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/dict_phone/lexicon.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/dict_phone/lexicon.txt is OK</span><br><br>Checking data/dict_phone/extra_questions.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/dict_phone/extra_questions.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/dict_phone/extra_questions.txt is OK</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">SUCCESS [validating dictionary directory data/dict_phone]</span><br><br>**Creating data/dict_phone/lexiconp.txt from data/dict_phone/lexicon.txt<br>fstaddselfloops data/lang_phone/phones/wdisambig_phones.int data/lang_phone/phones/wdisambig_words.int <br>prepare_lang.sh: validating output directory<br>utils/validate_lang.pl data/lang_phone<br>Checking existence of separator file<br>separator file data/lang_phone/subword_separator.txt is empty or does not exist, deal in word case.<br>Checking data/lang_phone/phones.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones.txt is OK</span><br><br>Checking words.txt: #0 ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/words.txt is OK</span><br><br>Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">silence.txt and nonsilence.txt are disjoint</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">silence.txt and disambig.txt are disjoint</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">disambig.txt and nonsilence.txt are disjoint</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">disjoint property is OK</span><br><br>Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">found no unexplainable phones <span class="hljs-keyword">in</span> phones.txt</span><br><br>Checking data/lang_phone/phones/context_indep.&#123;txt, int, csl&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">1 entry/entries <span class="hljs-keyword">in</span> data/lang_phone/phones/context_indep.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/context_indep.int corresponds to data/lang_phone/phones/context_indep.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/context_indep.csl corresponds to data/lang_phone/phones/context_indep.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/context_indep.&#123;txt, int, csl&#125; are OK</span><br><br>Checking data/lang_phone/phones/nonsilence.&#123;txt, int, csl&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">217 entry/entries <span class="hljs-keyword">in</span> data/lang_phone/phones/nonsilence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/nonsilence.int corresponds to data/lang_phone/phones/nonsilence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/nonsilence.csl corresponds to data/lang_phone/phones/nonsilence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/nonsilence.&#123;txt, int, csl&#125; are OK</span><br><br>Checking data/lang_phone/phones/silence.&#123;txt, int, csl&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">1 entry/entries <span class="hljs-keyword">in</span> data/lang_phone/phones/silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/silence.int corresponds to data/lang_phone/phones/silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/silence.csl corresponds to data/lang_phone/phones/silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/silence.&#123;txt, int, csl&#125; are OK</span><br><br>Checking data/lang_phone/phones/optional_silence.&#123;txt, int, csl&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">1 entry/entries <span class="hljs-keyword">in</span> data/lang_phone/phones/optional_silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/optional_silence.int corresponds to data/lang_phone/phones/optional_silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/optional_silence.csl corresponds to data/lang_phone/phones/optional_silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/optional_silence.&#123;txt, int, csl&#125; are OK</span><br><br>Checking data/lang_phone/phones/disambig.&#123;txt, int, csl&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">4 entry/entries <span class="hljs-keyword">in</span> data/lang_phone/phones/disambig.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/disambig.int corresponds to data/lang_phone/phones/disambig.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/disambig.csl corresponds to data/lang_phone/phones/disambig.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/disambig.&#123;txt, int, csl&#125; are OK</span><br><br>Checking data/lang_phone/phones/roots.&#123;txt, int&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">218 entry/entries <span class="hljs-keyword">in</span> data/lang_phone/phones/roots.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/roots.int corresponds to data/lang_phone/phones/roots.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/roots.&#123;txt, int&#125; are OK</span><br><br>Checking data/lang_phone/phones/sets.&#123;txt, int&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">218 entry/entries <span class="hljs-keyword">in</span> data/lang_phone/phones/sets.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/sets.int corresponds to data/lang_phone/phones/sets.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/sets.&#123;txt, int&#125; are OK</span><br><br>Checking data/lang_phone/phones/extra_questions.&#123;txt, int&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">7 entry/entries <span class="hljs-keyword">in</span> data/lang_phone/phones/extra_questions.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/extra_questions.int corresponds to data/lang_phone/phones/extra_questions.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/extra_questions.&#123;txt, int&#125; are OK</span><br><br>Checking optional_silence.txt ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">reading data/lang_phone/phones/optional_silence.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/optional_silence.txt is OK</span><br><br>Checking disambiguation symbols: #0 and #1<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/disambig.txt has <span class="hljs-string">&quot;#0&quot;</span> and <span class="hljs-string">&quot;#1&quot;</span></span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/disambig.txt is OK</span><br><br>Checking topo ...<br><br>Checking word-level disambiguation symbols...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/phones/wdisambig.txt exists (newer prepare_lang.sh)</span><br>Checking data/lang_phone/oov.&#123;txt, int&#125; ...<br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text seems to be UTF-8 or ASCII, checking whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">text contains only allowed whitespaces</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">1 entry/entries <span class="hljs-keyword">in</span> data/lang_phone/oov.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/oov.int corresponds to data/lang_phone/oov.txt</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/oov.&#123;txt, int&#125; are OK</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/L.fst is olabel sorted</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">data/lang_phone/L_disambig.fst is olabel sorted</span><br><span class="hljs-meta prompt_">--&gt; </span><span class="language-bash">SUCCESS [validating lang directory data/lang_phone]</span><br>Converting &#x27;data/graph_phone/phone.3gram.lm.gz&#x27; to FST<br>arpa2fst --disambig-symbol=#0 --read-symbol-table=data/graph_phone/lang/words.txt - data/graph_phone/lang/G.fst <br>LOG (arpa2fst[5.5.1050~1-0fb50]:Read():arpa-file-parser.cc:94) Reading \data\ section.<br>LOG (arpa2fst[5.5.1050~1-0fb50]:Read():arpa-file-parser.cc:149) Reading \1-grams: section.<br>LOG (arpa2fst[5.5.1050~1-0fb50]:Read():arpa-file-parser.cc:149) Reading \2-grams: section.<br>LOG (arpa2fst[5.5.1050~1-0fb50]:Read():arpa-file-parser.cc:149) Reading \3-grams: section.<br>LOG (arpa2fst[5.5.1050~1-0fb50]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 5709 to 4848<br>fstisstochastic data/graph_phone/lang/G.fst <br>1.86678e-07 -3.76792<br>Succeeded in formatting LM: &#x27;data/graph_phone/phone.3gram.lm.gz&#x27;<br></code></pre></td></tr></table></figure>

<h3 id="单音素模型训练"><a href="#单音素模型训练" class="headerlink" title="单音素模型训练"></a>单音素模型训练</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">step4:单音素模型训练(tri0)、解码、对齐</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">monophone</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">train_mono.sh:用来训练单音素隐马尔科夫模型，一共进行40次迭代，每两次迭代进行一次对齐操作。</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">过程之道：初始化模型-&gt;生成训练图HCLG.fst-&gt;对标签进行初始化对齐-&gt;统计估计模型所需的统计量-&gt;估计参数得到新模型-&gt;迭代训练-&gt;最后的模型final.mdl。</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">data/mfcc/train:输入，用于训练的数据；data/lang:输入，语言模型。monophone模型的训练需要用到phones.txt这个文件;exp/mono：输出，单音素模型，一些日志和对齐文件，主要输出为final.mdl和tree</span><br>steps/train_mono.sh --boost-silence 1.25 --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/train data/lang exp/mono || exit 1;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">test</span> monophone model</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">thchs-30_decode.sh:测试单音素模型，解码和测试部分，它采用刚刚训练得到的模型来对测试数据集进行解码并计算准确率等信息，实际使用mkgraph.sh建立完全的识别网络，并输出一个有限状态转换器，最后使用decode.sh以语言模型和测试数据为输入计算WER。</span><br>local/thchs-30_decode.sh --mono true --nj $n &quot;steps/decode.sh&quot; exp/mono data/mfcc &amp;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">monophone_ali</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">align_si.sh：这一步是为了三音素训练提供对齐基础。用指定src-dir中的模型对指定data-dir中的数据进行对齐，一般在训练新模型前进行，以上一版本模型作为输入，输出在&lt;align-dir&gt;。</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">--boost-silence 1.25：在对齐过程中提高静音的比例；data/mfcc/train：输入，标注文本text;data/lang：输入，词典L.fst;exp/mono：输入，模型，tree文件；输出：对齐序列</span><br>steps/align_si.sh --boost-silence 1.25 --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/train data/lang exp/mono exp/mono_ali || exit 1;<br></code></pre></td></tr></table></figure>

<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220901084916751.png" srcset="/img/loading.gif" lazyload alt="image-20220901084916751"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs shell">steps/train_mono.sh --boost-silence 1.25 --nj 8 --cmd run.pl data/mfcc/train data/lang exp/mono<br>steps/train_mono.sh: Initializing monophone system.<br>steps/train_mono.sh: Compiling training graphs<br>steps/train_mono.sh: Aligning data equally (pass 0)<br>steps/train_mono.sh: Pass 1<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 2<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 3<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 4<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 5<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 6<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 7<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 8<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 9<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 10<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 11<br>steps/train_mono.sh: Pass 12<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 13<br>steps/train_mono.sh: Pass 14<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 15<br>steps/train_mono.sh: Pass 16<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 17<br>steps/train_mono.sh: Pass 18<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 19<br>steps/train_mono.sh: Pass 20<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 21<br>steps/train_mono.sh: Pass 22<br>steps/train_mono.sh: Pass 23<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 24<br>steps/train_mono.sh: Pass 25<br>steps/train_mono.sh: Pass 26<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 27<br>steps/train_mono.sh: Pass 28<br>steps/train_mono.sh: Pass 29<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 30<br>steps/train_mono.sh: Pass 31<br>steps/train_mono.sh: Pass 32<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 33<br>steps/train_mono.sh: Pass 34<br>steps/train_mono.sh: Pass 35<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 36<br>steps/train_mono.sh: Pass 37<br>steps/train_mono.sh: Pass 38<br>steps/train_mono.sh: Aligning data<br>steps/train_mono.sh: Pass 39<br>steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/mono<br>steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log<br>3976 warnings in exp/mono/log/align.*.*.log<br>56 warnings in exp/mono/log/acc.*.*.log<br>1053 warnings in exp/mono/log/update.*.log<br>exp/mono: nj=8 align prob=-100.09 over 25.49h [retry=0.2%, fail=0.0%] states=656 gauss=990<br>steps/train_mono.sh: Done training monophone system in exp/mono<br></code></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">steps/align_si.sh --boost-silence 1.25 --nj 8 --cmd run.pl data/mfcc/train data/lang exp/mono exp/mono_ali<br>using monophone to generate graph<br>WARNING: the --mono, --left-biphone and --quinphone options are now deprecated and ignored.<br>tree-info exp/mono/tree <br>tree-info exp/mono/tree <br>steps/align_si.sh: feature type is delta<br>steps/align_si.sh: aligning data in data/mfcc/train using model from exp/mono, putting alignments in exp/mono_ali<br>fstminimizeencoded <br>fstpushspecial <br>fstdeterminizestar --use-log=true <br>fsttablecompose data/graph/lang/L_disambig.fst data/graph/lang/G.fst <br>steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/mono_ali<br>steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali/log/analyze_alignments.log<br>steps/align_si.sh: done aligning data.<br></code></pre></td></tr></table></figure>

<h3 id="三音素模型训练"><a href="#三音素模型训练" class="headerlink" title="三音素模型训练"></a>三音素模型训练</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">triphone</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">steps/train_deltas.sh就是三音素模型的训练部分，三音素的训练和单音素模型的主要区别是状态绑定部分</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">Usage: steps/train_deltas.sh &lt;num-leaves&gt; &lt;tot-gauss&gt; &lt;data-dir&gt; &lt;lang-dir&gt; &lt;alignment-dir&gt; &lt;exp-dir&gt;</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">num-leaves：叶子节点数目；tot-gauss：总高斯数目；data-dir：数据文件夹；lang-dir：存放语言的文件夹；alignment-dir：存放之前单音素对齐后结果的文件夹；exp-dir是存放三音素模型结果的文件夹。</span><br>steps/train_deltas.sh --boost-silence 1.25 --cmd &quot;$train_cmd&quot; 2000 10000 data/mfcc/train data/lang exp/mono_ali exp/tri1 || exit 1;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">test</span> tri1 model</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">解码测试部分，可以看到该代码和单音素的解码测试是一样的，只是少了–mono选项</span><br>local/thchs-30_decode.sh --nj $n &quot;steps/decode.sh&quot; exp/tri1 data/mfcc &amp;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">triphone_ali</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">利用第一行训练得到的三音素模型来做强制对齐。代码也是和单音素时是一样的，只是输出模型的变化</span><br>steps/align_si.sh --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/train data/lang exp/tri1 exp/tri1_ali || exit 1;<br></code></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs shell">steps/train_deltas.sh --boost-silence 1.25 --cmd run.pl 2000 10000 data/mfcc/train data/lang exp/mono_ali exp/tri1<br>steps/train_deltas.sh: accumulating tree stats<br>steps/train_deltas.sh: getting questions for tree-building, via clustering<br>steps/train_deltas.sh: building the tree<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 109 with no stats; corresponding phone list: 110 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 121 with no stats; corresponding phone list: 122 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 163 with no stats; corresponding phone list: 164 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 175 with no stats; corresponding phone list: 176 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 176 with no stats; corresponding phone list: 177 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 177 with no stats; corresponding phone list: 178 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 182 with no stats; corresponding phone list: 183 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 203 with no stats; corresponding phone list: 204 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 208 with no stats; corresponding phone list: 209 <br>** The warnings above about &#x27;no stats&#x27; generally mean you have phones **<br>** (or groups of phones) in your phone set that had no corresponding data. **<br>** You should probably figure out whether something went wrong, **<br>** or whether your data just doesn&#x27;t happen to have examples of those **<br>** phones. **<br>steps/train_deltas.sh: converting alignments from exp/mono_ali to use current tree<br>steps/train_deltas.sh: compiling graphs of transcripts<br>steps/train_deltas.sh: training pass 1<br>steps/train_deltas.sh: training pass 2<br>steps/train_deltas.sh: training pass 3<br>steps/train_deltas.sh: training pass 4<br>steps/train_deltas.sh: training pass 5<br>steps/train_deltas.sh: training pass 6<br>steps/train_deltas.sh: training pass 7<br>steps/train_deltas.sh: training pass 8<br>steps/train_deltas.sh: training pass 9<br>steps/train_deltas.sh: training pass 10<br>steps/train_deltas.sh: aligning data<br>steps/train_deltas.sh: training pass 11<br>steps/train_deltas.sh: training pass 12<br>steps/train_deltas.sh: training pass 13<br>steps/train_deltas.sh: training pass 14<br>fstisstochastic data/graph/lang/tmp/LG.fst <br>-0.0480882 -0.0488869<br>[info]: LG not stochastic.<br>fstcomposecontext --context-size=1 --central-position=0 --read-disambig-syms=data/graph/lang/phones/disambig.int --write-disambig-syms=data/graph/lang/tmp/disambig_ilabels_1_0.int data/graph/lang/tmp/ilabels_1_0.499669 data/graph/lang/tmp/LG.fst <br>steps/train_deltas.sh: training pass 15<br>steps/train_deltas.sh: training pass 16<br>steps/train_deltas.sh: training pass 17<br>steps/train_deltas.sh: training pass 18<br>steps/train_deltas.sh: training pass 19<br>steps/train_deltas.sh: training pass 20<br>steps/train_deltas.sh: aligning data<br>fstisstochastic data/graph/lang/tmp/CLG_1_0.fst <br>-0.0480882 -0.0488869<br>[info]: CLG not stochastic.<br>make-h-transducer --disambig-syms-out=exp/mono/graph_word/disambig_tid.int --transition-scale=1.0 data/graph/lang/tmp/ilabels_1_0 exp/mono/tree exp/mono/final.mdl <br>fsttablecompose exp/mono/graph_word/Ha.fst data/graph/lang/tmp/CLG_1_0.fst <br>fstminimizeencoded <br>fstrmepslocal <br>fstrmsymbols exp/mono/graph_word/disambig_tid.int <br>fstdeterminizestar --use-log=true <br>steps/train_deltas.sh: training pass 21<br>steps/train_deltas.sh: training pass 22<br>steps/train_deltas.sh: training pass 23<br>steps/train_deltas.sh: training pass 24<br>steps/train_deltas.sh: training pass 25<br>steps/train_deltas.sh: training pass 26<br>steps/train_deltas.sh: training pass 27<br>steps/train_deltas.sh: training pass 28<br>steps/train_deltas.sh: training pass 29<br>steps/train_deltas.sh: training pass 30<br>steps/train_deltas.sh: aligning data<br>steps/train_deltas.sh: training pass 31<br>steps/train_deltas.sh: training pass 32<br>steps/train_deltas.sh: training pass 33<br>steps/train_deltas.sh: training pass 34<br>steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri1<br>steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log<br>9 warnings in exp/tri1/log/questions.log<br>1 warnings in exp/tri1/log/compile_questions.log<br>9 warnings in exp/tri1/log/init_model.log<br>74 warnings in exp/tri1/log/acc.*.*.log<br>93 warnings in exp/tri1/log/align.*.*.log<br>281 warnings in exp/tri1/log/update.*.log<br>1 warnings in exp/tri1/log/build_tree.log<br>exp/tri1: nj=8 align prob=-96.76 over 25.48h [retry=0.4%, fail=0.0%] states=1680 gauss=10026 tree-impr=4.80<br>steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1<br></code></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">steps/align_si.sh --nj 8 --cmd run.pl data/mfcc/train data/lang exp/tri1 exp/tri1_ali<br>tree-info exp/tri1/tree <br>tree-info exp/tri1/tree <br>steps/align_si.sh: feature type is delta<br>steps/align_si.sh: aligning data in data/mfcc/train using model from exp/tri1, putting alignments in exp/tri1_ali<br>fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/graph/lang/phones/disambig.int --write-disambig-syms=data/graph/lang/tmp/disambig_ilabels_3_1.int data/graph/lang/tmp/ilabels_3_1.506942 data/graph/lang/tmp/LG.fst <br>steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri1_ali<br>steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali/log/analyze_alignments.log<br>steps/align_si.sh: done aligning data.<br></code></pre></td></tr></table></figure>

<h3 id="最大似然线性变换"><a href="#最大似然线性变换" class="headerlink" title="最大似然线性变换"></a>最大似然线性变换</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">lda_mllt</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">最大似然线性变换</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">用来做特征调整并训练新模型</span><br>steps/train_lda_mllt.sh --cmd &quot;$train_cmd&quot; --splice-opts &quot;--left-context=3 --right-context=3&quot; 2500 15000 data/mfcc/train data/lang exp/tri1_ali exp/tri2b || exit 1;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">test</span> tri2b model</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">解码测试</span><br>local/thchs-30_decode.sh --nj $n &quot;steps/decode.sh&quot; exp/tri2b data/mfcc &amp;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">lda_mllt_ali</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">根据模型对数据进行对齐</span><br>steps/align_si.sh  --nj $n --cmd &quot;$train_cmd&quot; --use-graphs true data/mfcc/train data/lang exp/tri2b exp/tri2b_ali || exit 1;<br></code></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br></pre></td><td class="code"><pre><code class="hljs shell">steps/train_lda_mllt.sh --cmd run.pl --splice-opts --left-context=3 --right-context=3 2500 15000 data/mfcc/train data/lang exp/tri1_ali exp/tri2b<br>steps/train_lda_mllt.sh: Accumulating LDA statistics.<br>fstisstochastic data/graph/lang/tmp/CLG_3_1.fst <br>steps/train_lda_mllt.sh: Accumulating tree stats<br>0 -0.0488869<br>[info]: CLG not stochastic.<br>make-h-transducer --disambig-syms-out=exp/tri1/graph_word/disambig_tid.int --transition-scale=1.0 data/graph/lang/tmp/ilabels_3_1 exp/tri1/tree exp/tri1/final.mdl <br>fstminimizeencoded <br>fstrmepslocal <br>fstrmsymbols exp/tri1/graph_word/disambig_tid.int <br>fsttablecompose exp/tri1/graph_word/Ha.fst data/graph/lang/tmp/CLG_3_1.fst <br>fstdeterminizestar --use-log=true <br>steps/train_lda_mllt.sh: Getting questions for tree clustering.<br>steps/train_lda_mllt.sh: Building the tree<br>steps/train_lda_mllt.sh: Initializing the model<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 109 with no stats; corresponding phone list: 110 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 121 with no stats; corresponding phone list: 122 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 163 with no stats; corresponding phone list: 164 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 175 with no stats; corresponding phone list: 176 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 176 with no stats; corresponding phone list: 177 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 177 with no stats; corresponding phone list: 178 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 203 with no stats; corresponding phone list: 204 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 208 with no stats; corresponding phone list: 209 <br>This is a bad warning.<br>steps/train_lda_mllt.sh: Converting alignments from exp/tri1_ali to use current tree<br>steps/train_lda_mllt.sh: Compiling graphs of transcripts<br>Training pass 1<br>fstisstochastic exp/mono/graph_word/HCLGa.fst <br>Training pass 2<br>steps/train_lda_mllt.sh: Estimating MLLT<br>0.644531 -0.0974261<br>HCLGa is not stochastic<br>add-self-loops --self-loop-scale=0.1 --reorder=true exp/mono/final.mdl exp/mono/graph_word/HCLGa.fst <br>Training pass 3<br>Training pass 4<br>steps/train_lda_mllt.sh: Estimating MLLT<br>Training pass 5<br>Training pass 6<br>steps/train_lda_mllt.sh: Estimating MLLT<br>Training pass 7<br>Training pass 8<br>Training pass 9<br>Training pass 10<br>Aligning data<br>steps/decode.sh --cmd run.pl --mem 4G --nj 8 exp/mono/graph_word data/mfcc/test exp/mono/decode_test_word<br>decode.sh: feature type is delta<br>Training pass 11<br>Training pass 12<br>steps/train_lda_mllt.sh: Estimating MLLT<br>Training pass 13<br>Training pass 14<br>Training pass 15<br>Training pass 16<br>Training pass 17<br>Training pass 18<br>Training pass 19<br>Training pass 20<br>Aligning data<br>Training pass 21<br>Training pass 22<br>Training pass 23<br>Training pass 24<br>Training pass 25<br>Training pass 26<br>Training pass 27<br>Training pass 28<br>Training pass 29<br>Training pass 30<br>Aligning data<br>Training pass 31<br>Training pass 32<br>Training pass 33<br>Training pass 34<br>steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri2b<br>steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b/log/analyze_alignments.log<br>272 warnings in exp/tri2b/log/update.*.log<br>9 warnings in exp/tri2b/log/init_model.log<br>147 warnings in exp/tri2b/log/align.*.*.log<br>3 warnings in exp/tri2b/log/lda_acc.*.log<br>1 warnings in exp/tri2b/log/compile_questions.log<br>102 warnings in exp/tri2b/log/acc.*.*.log<br>1 warnings in exp/tri2b/log/build_tree.log<br>8 warnings in exp/tri2b/log/questions.log<br>exp/tri2b: nj=8 align prob=-48.15 over 25.48h [retry=0.5%, fail=0.0%] states=2080 gauss=15034 tree-impr=4.34 lda-sum=23.95 mllt:impr,logdet=1.18,1.68<br>steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/tri2b<br>steps/align_si.sh --nj 8 --cmd run.pl --use-graphs true data/mfcc/train data/lang exp/tri2b exp/tri2b_ali<br>tree-info exp/tri2b/tree <br>tree-info exp/tri2b/tree <br>steps/align_si.sh: feature type is lda<br>steps/align_si.sh: aligning data in data/mfcc/train using model from exp/tri2b, putting alignments in exp/tri2b_ali<br>make-h-transducer --disambig-syms-out=exp/tri2b/graph_word/disambig_tid.int --transition-scale=1.0 data/graph/lang/tmp/ilabels_3_1 exp/tri2b/tree exp/tri2b/final.mdl <br>fstrmsymbols exp/tri2b/graph_word/disambig_tid.int <br>fstrmepslocal <br>fsttablecompose exp/tri2b/graph_word/Ha.fst data/graph/lang/tmp/CLG_3_1.fst <br>fstminimizeencoded <br>fstdeterminizestar --use-log=true <br>utils/mkgraph.sh: line 145: 507716 Done                    fsttablecompose $dir/Ha.fst &quot;$clg&quot;<br>     507717                       | fstdeterminizestar --use-log=true<br>     507718                       | fstrmsymbols $dir/disambig_tid.int<br>     507719                       | fstrmepslocal<br>     507720 Killed                  | fstminimizeencoded &gt; $dir/HCLGa.fst.$$<br>steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri2b_ali<br>steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b_ali/log/analyze_alignments.log<br>steps/align_si.sh: done aligning data.<br>steps/train_sat.sh --cmd run.pl 2500 15000 data/mfcc/train data/lang exp/tri2b_ali exp/tri3b<br>steps/train_sat.sh: feature type is lda<br>steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri2b_ali<br>steps/train_sat.sh: Accumulating tree stats<br>steps/train_sat.sh: Getting questions for tree clustering.<br>steps/train_sat.sh: Building the tree<br>steps/train_sat.sh: Initializing the model<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 109 with no stats; corresponding phone list: 110 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 121 with no stats; corresponding phone list: 122 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 163 with no stats; corresponding phone list: 164 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 175 with no stats; corresponding phone list: 176 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 176 with no stats; corresponding phone list: 177 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 177 with no stats; corresponding phone list: 178 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 203 with no stats; corresponding phone list: 204 <br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 208 with no stats; corresponding phone list: 209 <br>This is a bad warning.<br>steps/train_sat.sh: Converting alignments from exp/tri2b_ali to use current tree<br>steps/train_sat.sh: Compiling graphs of transcripts<br>ERROR: VectorFst::Read: Read failed: &lt;unspecified&gt;<br>ERROR (fstdeterminizestar[5.5.1050~1-0fb50]:ReadFstKaldi():kaldi-fst-io.cc:40) Could not read fst from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7f78f14ef1ce]<br>fstdeterminizestar(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x55575df6e59d]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldi(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)+0x370) [0x7f78f1553680]<br>fstdeterminizestar(main+0x244) [0x55575df6c47c]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7f78f0df9d90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7f78f0df9e40]<br>fstdeterminizestar(_start+0x25) [0x55575df6c165]<br><br>kaldi::KaldiFatalErrorERROR: FstHeader::Read: Bad FST header: -<br>ERROR (fstrmsymbols[5.5.1050~1-0fb50]:ReadFstKaldiGeneric():kaldi-fst-io.cc:59) Reading FST: error reading FST header from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7ff8b14a71ce]<br>fstrmsymbols(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x560291e95761]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldiGeneric(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, bool)+0x1c5) [0x7ff8b150abd1]<br>fstrmsymbols(main+0x30d) [0x560291e94bb6]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7ff8b0e98d90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7ff8b0e98e40]<br>fstrmsymbols(_start+0x25) [0x560291e947e5]<br><br>kaldi::KaldiFatalErrorERROR: FstHeader::Read: Bad FST header: -<br>ERROR (fstrmepslocal[5.5.1050~1-0fb50]:ReadFstKaldi():kaldi-fst-io.cc:35) Reading FST: error reading FST header from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7f1c1e8481ce]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x7f1c1e8ad5fd]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldi(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)+0x1ba) [0x7f1c1e8ac4ca]<br>fstrmepslocal(main+0x1b3) [0x557ea3dd9b7c]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7f1c1e152d90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7f1c1e152e40]<br>fstrmepslocal(_start+0x25) [0x557ea3dd9905]<br><br>kaldi::KaldiFatalErrorERROR: FstHeader::Read: Bad FST header: -<br>ERROR (fstminimizeencoded[5.5.1050~1-0fb50]:ReadFstKaldi():kaldi-fst-io.cc:35) Reading FST: error reading FST header from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7f4e659871ce]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x7f4e659ec5fd]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldi(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)+0x1ba) [0x7f4e659eb4ca]<br>fstminimizeencoded(main+0x111) [0x558b27419b5a]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7f4e65378d90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7f4e65378e40]<br>fstminimizeencoded(_start+0x25) [0x558b27419985]<br><br>kaldi::KaldiFatalErrorPass 1<br>Pass 2<br>Estimating fMLLR transforms<br>Pass 3<br>Pass 4<br>Estimating fMLLR transforms<br>Pass 5<br>Pass 6<br>Estimating fMLLR transforms<br>Pass 7<br>Pass 8<br>Pass 9<br>Pass 10<br>Aligning data<br>Pass 11<br>Pass 12<br>Estimating fMLLR transforms<br>Pass 13<br>Pass 14<br>Pass 15<br>Pass 16<br>Pass 17<br>Pass 18<br>Pass 19<br>Pass 20<br>Aligning data<br>Pass 21<br>Pass 22<br>Pass 23<br>Pass 24<br>Pass 25<br>Pass 26<br>Pass 27<br>Pass 28<br>Pass 29<br>Pass 30<br>Aligning data<br>Pass 31<br>Pass 32<br>Pass 33<br>Pass 34<br>steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri3b<br>steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b/log/analyze_alignments.log<br>273 warnings in exp/tri3b/log/update.*.log<br>9 warnings in exp/tri3b/log/init_model.log<br>8 warnings in exp/tri3b/log/questions.log<br>137 warnings in exp/tri3b/log/acc.*.*.log<br>1 warnings in exp/tri3b/log/compile_questions.log<br>17 warnings in exp/tri3b/log/fmllr.*.*.log<br>1 warnings in exp/tri3b/log/build_tree.log<br>8 warnings in exp/tri3b/log/est_alimdl.log<br>184 warnings in exp/tri3b/log/align.*.*.log<br>steps/train_sat.sh: Likelihood evolution:<br>-49.6847 -49.47 -49.3759 -49.1992 -48.6433 -48.0719 -47.7074 -47.4761 -47.3067 -46.8607 -46.6761 -46.4768 -46.3598 -46.2623 -46.1698 -46.0852 -46.0069 -45.9349 -45.8688 -45.714 -45.6215 -45.5655 -45.513 -45.4636 -45.4176 -45.372 -45.3275 -45.2854 -45.2456 -45.1544 -45.0968 -45.0729 -45.0593 -45.05 <br>exp/tri3b: nj=8 align prob=-47.86 over 25.48h [retry=0.6%, fail=0.0%] states=2096 gauss=15027 fmllr-impr=2.42 over 18.96h tree-impr=6.40<br></code></pre></td></tr></table></figure>

<h3 id="说话人自适应训练"><a href="#说话人自适应训练" class="headerlink" title="说话人自适应训练"></a>说话人自适应训练</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">sat</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">说话人自适应训练</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">对特征进行FMLLR，而后训练GMM模型</span><br>steps/train_sat.sh --cmd &quot;$train_cmd&quot; 2500 15000 data/mfcc/train data/lang exp/tri2b_ali exp/tri3b || exit 1;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">test</span> tri3b model</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">对自适应模型的解码及测试</span><br>local/thchs-30_decode.sh --nj $n &quot;steps/decode_fmllr.sh&quot; exp/tri3b data/mfcc &amp;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">sat_ali</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">根据FMLLR模型对数据进行对齐可以看出核心任务是对特征码本做FMLLR以达到说话人自适应的目的</span><br>steps/align_fmllr.sh --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/train data/lang exp/tri3b exp/tri3b_ali || exit 1;<br></code></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs shell">steps/train_sat.sh: done training SAT system in exp/tri3b<br>steps/align_fmllr.sh --nj 8 --cmd run.pl data/mfcc/train data/lang exp/tri3b exp/tri3b_ali<br>tree-info exp/tri3b/tree <br>tree-info exp/tri3b/tree <br>steps/align_fmllr.sh: feature type is lda<br>steps/align_fmllr.sh: compiling training graphs<br>make-h-transducer --disambig-syms-out=exp/tri3b/graph_word/disambig_tid.int --transition-scale=1.0 data/graph/lang/tmp/ilabels_3_1 exp/tri3b/tree exp/tri3b/final.mdl <br>fstrmepslocal <br>fstrmsymbols exp/tri3b/graph_word/disambig_tid.int <br>fstdeterminizestar --use-log=true <br>fstminimizeencoded <br>fsttablecompose exp/tri3b/graph_word/Ha.fst data/graph/lang/tmp/CLG_3_1.fst <br>steps/align_fmllr.sh: aligning data in data/mfcc/train using exp/tri3b/final.alimdl and speaker-independent features.<br>steps/align_fmllr.sh: computing fMLLR transforms<br>steps/align_fmllr.sh: doing final alignment.<br>ERROR: VectorFst::Read: Read failed: &lt;unspecified&gt;<br>ERROR (fstdeterminizestar[5.5.1050~1-0fb50]:ReadFstKaldi():kaldi-fst-io.cc:40) Could not read fst from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7feaa1b411ce]<br>fstdeterminizestar(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x5570571aa59d]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldi(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)+0x370) [0x7feaa1ba5680]<br>fstdeterminizestar(main+0x244) [0x5570571a847c]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7feaa144bd90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7feaa144be40]<br>fstdeterminizestar(_start+0x25) [0x5570571a8165]<br><br>kaldi::KaldiFatalErrorERROR: FstHeader::Read: Bad FST header: -<br>ERROR (fstrmsymbols[5.5.1050~1-0fb50]:ReadFstKaldiGeneric():kaldi-fst-io.cc:59) Reading FST: error reading FST header from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7f88614231ce]<br>fstrmsymbols(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x55a985f28761]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldiGeneric(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, bool)+0x1c5) [0x7f8861486bd1]<br>fstrmsymbols(main+0x30d) [0x55a985f27bb6]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7f8860e14d90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7f8860e14e40]<br>fstrmsymbols(_start+0x25) [0x55a985f277e5]<br><br>kaldi::KaldiFatalErrorERROR: FstHeader::Read: Bad FST header: -<br>ERROR (fstrmepslocal[5.5.1050~1-0fb50]:ReadFstKaldi():kaldi-fst-io.cc:35) Reading FST: error reading FST header from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7fc71e2011ce]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x7fc71e2665fd]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldi(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)+0x1ba) [0x7fc71e2654ca]<br>fstrmepslocal(main+0x1b3) [0x56487be61b7c]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7fc71db0bd90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7fc71db0be40]<br>fstrmepslocal(_start+0x25) [0x56487be61905]<br><br>kaldi::KaldiFatalErrorERROR: FstHeader::Read: Bad FST header: -<br>ERROR (fstminimizeencoded[5.5.1050~1-0fb50]:ReadFstKaldi():kaldi-fst-io.cc:35) Reading FST: error reading FST header from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7f90cf9541ce]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x7f90cf9b95fd]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldi(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)+0x1ba) [0x7f90cf9b84ca]<br>fstminimizeencoded(main+0x111) [0x55649f117b5a]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7f90cf345d90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7f90cf345e40]<br>fstminimizeencoded(_start+0x25) [0x55649f117985]<br><br>kaldi::KaldiFatalErrorsteps/align_fmllr.sh: done aligning data.<br>steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri3b_ali<br>steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali/log/analyze_alignments.log<br>3 warnings in exp/tri3b_ali/log/fmllr.*.log<br>61 warnings in exp/tri3b_ali/log/align_pass2.*.log<br>45 warnings in exp/tri3b_ali/log/align_pass1.*.log<br></code></pre></td></tr></table></figure>



<h3 id="quick模型训练"><a href="#quick模型训练" class="headerlink" title="quick模型训练"></a>quick模型训练</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">quick</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">quick模型训练</span><br>steps/train_quick.sh --cmd &quot;$train_cmd&quot; 4200 40000 data/mfcc/train data/lang exp/tri3b_ali exp/tri4b || exit 1;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">对quick训练得到的模型进行解码测试</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">test</span> tri4b model</span><br>local/thchs-30_decode.sh --nj $n &quot;steps/decode_fmllr.sh&quot; exp/tri4b data/mfcc &amp;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">采用quick训练得到的模型对数据进行对齐</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">quick_ali</span><br>steps/align_fmllr.sh --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/train data/lang exp/tri4b exp/tri4b_ali || exit 1;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">对开发数据集进行对齐</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">quick_ali_cv</span><br>steps/align_fmllr.sh --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/dev data/lang exp/tri4b exp/tri4b_ali_cv || exit 1;<br></code></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs shell">steps/train_quick.sh --cmd run.pl 4200 40000 data/mfcc/train data/lang exp/tri3b_ali exp/tri4b<br>steps/train_quick.sh: feature type is lda<br>steps/train_quick.sh: using transforms from exp/tri3b_ali<br>steps/train_quick.sh: accumulating tree stats<br>steps/train_quick.sh: Getting questions for tree clustering.<br>steps/train_quick.sh: Building the tree<br>steps/train_quick.sh: Initializing the model<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmmFromOld():gmm-init-model.cc:147) Leaf 109 of new tree has no stats.<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmmFromOld():gmm-init-model.cc:147) Leaf 121 of new tree has no stats.<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmmFromOld():gmm-init-model.cc:147) Leaf 163 of new tree has no stats.<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmmFromOld():gmm-init-model.cc:147) Leaf 175 of new tree has no stats.<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmmFromOld():gmm-init-model.cc:147) Leaf 176 of new tree has no stats.<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmmFromOld():gmm-init-model.cc:147) Leaf 177 of new tree has no stats.<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmmFromOld():gmm-init-model.cc:147) Leaf 203 of new tree has no stats.<br>WARNING (gmm-init-model[5.5.1050~1-0fb50]:InitAmGmmFromOld():gmm-init-model.cc:147) Leaf 208 of new tree has no stats.<br>steps/train_quick.sh: This is a bad warning.<br>steps/train_quick.sh: mixing up old model.<br>steps/train_quick.sh: converting old alignments<br>steps/train_quick.sh: compiling training graphs<br>steps/train_quick.sh: pass 1<br>steps/train_quick.sh: pass 2<br>steps/train_quick.sh: pass 3<br>steps/train_quick.sh: pass 4<br>steps/train_quick.sh: pass 5<br>steps/train_quick.sh: pass 6<br>steps/train_quick.sh: pass 7<br>steps/train_quick.sh: pass 8<br>steps/train_quick.sh: pass 9<br>steps/train_quick.sh: pass 10<br>steps/train_quick.sh: aligning data<br>steps/train_quick.sh: pass 11<br>steps/train_quick.sh: pass 12<br>steps/train_quick.sh: pass 13<br>steps/train_quick.sh: pass 14<br>steps/train_quick.sh: pass 15<br>steps/train_quick.sh: aligning data<br>steps/train_quick.sh: pass 16<br>steps/train_quick.sh: pass 17<br>steps/train_quick.sh: pass 18<br>steps/train_quick.sh: pass 19<br>steps/train_quick.sh: estimating alignment model<br>Done<br></code></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br></pre></td><td class="code"><pre><code class="hljs shell">steps/align_fmllr.sh --nj 8 --cmd run.pl data/mfcc/train data/lang exp/tri4b exp/tri4b_ali<br>tree-info exp/tri4b/tree <br>tree-info exp/tri4b/tree <br>steps/align_fmllr.sh: feature type is lda<br>steps/align_fmllr.sh: compiling training graphs<br>make-h-transducer --disambig-syms-out=exp/tri4b/graph_word/disambig_tid.int --transition-scale=1.0 data/graph/lang/tmp/ilabels_3_1 exp/tri4b/tree exp/tri4b/final.mdl <br>fstrmsymbols exp/tri4b/graph_word/disambig_tid.int <br>fstrmepslocal <br>fstminimizeencoded <br>fstdeterminizestar --use-log=true <br>fsttablecompose exp/tri4b/graph_word/Ha.fst data/graph/lang/tmp/CLG_3_1.fst <br>steps/align_fmllr.sh: aligning data in data/mfcc/train using exp/tri4b/final.alimdl and speaker-independent features.<br>steps/align_fmllr.sh: computing fMLLR transforms<br>steps/align_fmllr.sh: doing final alignment.<br>ERROR: VectorFst::Read: Read failed: &lt;unspecified&gt;<br>ERROR (fstdeterminizestar[5.5.1050~1-0fb50]:ReadFstKaldi():kaldi-fst-io.cc:40) Could not read fst from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7f4d1b6ad1ce]<br>fstdeterminizestar(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x55ab2291f59d]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldi(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)+0x370) [0x7f4d1b711680]<br>fstdeterminizestar(main+0x244) [0x55ab2291d47c]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7f4d1afb7d90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7f4d1afb7e40]<br>fstdeterminizestar(_start+0x25) [0x55ab2291d165]<br><br>kaldi::KaldiFatalErrorERROR: FstHeader::Read: Bad FST header: -<br>ERROR (fstrmsymbols[5.5.1050~1-0fb50]:ReadFstKaldiGeneric():kaldi-fst-io.cc:59) Reading FST: error reading FST header from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7f1cacd2d1ce]<br>fstrmsymbols(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x55761aba4761]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldiGeneric(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, bool)+0x1c5) [0x7f1cacd90bd1]<br>fstrmsymbols(main+0x30d) [0x55761aba3bb6]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7f1cac71ed90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7f1cac71ee40]<br>fstrmsymbols(_start+0x25) [0x55761aba37e5]<br><br>kaldi::KaldiFatalErrorERROR: FstHeader::Read: Bad FST header: -<br>ERROR (fstrmepslocal[5.5.1050~1-0fb50]:ReadFstKaldi():kaldi-fst-io.cc:35) Reading FST: error reading FST header from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7fd966e901ce]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x7fd966ef55fd]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldi(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)+0x1ba) [0x7fd966ef44ca]<br>fstrmepslocal(main+0x1b3) [0x56524d4f7b7c]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7fd96679ad90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7fd96679ae40]<br>fstrmepslocal(_start+0x25) [0x56524d4f7905]<br><br>kaldi::KaldiFatalErrorERROR: FstHeader::Read: Bad FST header: -<br>ERROR (fstminimizeencoded[5.5.1050~1-0fb50]:ReadFstKaldi():kaldi-fst-io.cc:35) Reading FST: error reading FST header from standard input<br><br>[ Stack-Trace: ]<br>/home/baixf/kaldi/src/lib/libkaldi-base.so(kaldi::MessageLogger::LogMessage() const+0x70c) [0x7f2f0aba41ce]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(kaldi::MessageLogger::LogAndThrow::operator=(kaldi::MessageLogger const&amp;)+0x25) [0x7f2f0ac095fd]<br>/home/baixf/kaldi/src/lib/libkaldi-fstext.so(fst::ReadFstKaldi(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)+0x1ba) [0x7f2f0ac084ca]<br>fstminimizeencoded(main+0x111) [0x5628315c1b5a]<br>/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7f2f0a595d90]<br>/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7f2f0a595e40]<br>fstminimizeencoded(_start+0x25) [0x5628315c1985]<br><br>kaldi::KaldiFatalErrorsteps/align_fmllr.sh: done aligning data.<br>steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri4b_ali<br>steps/diagnostic/analyze_alignments.sh: see stats in exp/tri4b_ali/log/analyze_alignments.log<br>3 warnings in exp/tri4b_ali/log/fmllr.*.log<br>55 warnings in exp/tri4b_ali/log/align_pass2.*.log<br>47 warnings in exp/tri4b_ali/log/align_pass1.*.log<br>steps/align_fmllr.sh --nj 8 --cmd run.pl data/mfcc/dev data/lang exp/tri4b exp/tri4b_ali_cv<br>steps/align_fmllr.sh: feature type is lda<br>steps/align_fmllr.sh: compiling training graphs<br>steps/align_fmllr.sh: aligning data in data/mfcc/dev using exp/tri4b/final.alimdl and speaker-independent features.<br>steps/align_fmllr.sh: computing fMLLR transforms<br>steps/align_fmllr.sh: doing final alignment.<br>steps/align_fmllr.sh: done aligning data.<br>steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri4b_ali_cv<br>steps/diagnostic/analyze_alignments.sh: see stats in exp/tri4b_ali_cv/log/analyze_alignments.log<br>5 warnings in exp/tri4b_ali_cv/log/align_pass1.*.log<br>6 warnings in exp/tri4b_ali_cv/log/align_pass2.*.log<br>DNN training: stage 0: feature generation<br>producing fbank for train<br>steps/make_fbank.sh --nj 8 --cmd run.pl data/fbank/train exp/make_fbank/train fbank/train<br>utils/validate_data_dir.sh: Successfully validated data-directory data/fbank/train<br>steps/make_fbank.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>steps/make_fbank.sh: Succeeded creating filterbank features for train<br>steps/compute_cmvn_stats.sh data/fbank/train exp/fbank_cmvn/train fbank/train<br>Succeeded creating CMVN stats for train<br>producing fbank for dev<br>steps/make_fbank.sh --nj 8 --cmd run.pl data/fbank/dev exp/make_fbank/dev fbank/dev<br>utils/validate_data_dir.sh: Successfully validated data-directory data/fbank/dev<br>steps/make_fbank.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>steps/make_fbank.sh: Succeeded creating filterbank features for dev<br>steps/compute_cmvn_stats.sh data/fbank/dev exp/fbank_cmvn/dev fbank/dev<br>Succeeded creating CMVN stats for dev<br>producing fbank for test<br>Succeeded creating CMVN stats for test<br>producing test_fbank_phone<br><span class="hljs-meta prompt_"># </span><span class="language-bash">steps/nnet/train.sh --copy_feats <span class="hljs-literal">false</span> --cmvn-opts <span class="hljs-string">&quot;--norm-means=true --norm-vars=false&quot;</span> --hid-layers 4 --hid-dim 1024 --learn-rate 0.008 data/fbank/train data/fbank/dev data/lang exp/tri4b_ali exp/tri4b_ali_cv exp/tri4b_dnn</span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash">Started at Wed Aug 31 17:50:20 CST 2022</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"></span><br><span class="language-bash">steps/nnet/train.sh --copy_feats <span class="hljs-literal">false</span> --cmvn-opts --norm-means=<span class="hljs-literal">true</span> --norm-vars=<span class="hljs-literal">false</span> --hid-layers 4 --hid-dim 1024 --learn-rate 0.008 data/fbank/train data/fbank/dev data/lang exp/tri4b_ali exp/tri4b_ali_cv exp/tri4b_dnn</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">INFO</span><br>steps/nnet/train.sh : Training Neural Network<br>	 dir       : exp/tri4b_dnn <br>	 Train-set : data/fbank/train 10000, exp/tri4b_ali <br>	 CV-set    : data/fbank/dev 893 exp/tri4b_ali_cv <br><br>LOG ([5.5.1050~1-0fb50]:main():cuda-gpu-available.cc:61) <br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">## IS CUDA GPU AVAILABLE? &#x27;baixf-G3-3579&#x27; ###</span></span><br>WARNING ([5.5.1050~1-0fb50]:SelectGpuId():cu-device.cc:243) Not in compute-exclusive mode.  Suggestion: use &#x27;nvidia-smi -c 3&#x27; to set compute exclusive mode<br>LOG ([5.5.1050~1-0fb50]:SelectGpuIdAuto():cu-device.cc:438) Selecting from 1 GPUs<br>LOG ([5.5.1050~1-0fb50]:SelectGpuIdAuto():cu-device.cc:453) cudaSetDevice(0): NVIDIA GeForce GTX 1050	free:3992M, used:47M, total:4040M, free/total:0.98815<br>LOG ([5.5.1050~1-0fb50]:SelectGpuIdAuto():cu-device.cc:501) Device: 0, mem_ratio: 0.98815<br>LOG ([5.5.1050~1-0fb50]:SelectGpuId():cu-device.cc:382) Trying to select device: 0<br>LOG ([5.5.1050~1-0fb50]:SelectGpuIdAuto():cu-device.cc:511) Success selecting device 0 free mem ratio: 0.98815<br>LOG ([5.5.1050~1-0fb50]:FinalizeActiveGpu():cu-device.cc:338) The active GPU is [0]: NVIDIA GeForce GTX 1050free:3788M, used:251M, total:4040M, free/total:0.937657 version 6.1<br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">## HURRAY, WE GOT A CUDA GPU FOR COMPUTATION!!! ##</span></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">## Testing CUDA setup with a small computation (setup = cuda-toolkit + gpu-driver + kaldi):</span></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">## Test OK!</span></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">PREPARING ALIGNMENTS</span><br>Using PDF targets from dirs &#x27;exp/tri4b_ali&#x27; &#x27;exp/tri4b_ali_cv&#x27;<br>hmm-info exp/tri4b_ali/final.mdl <br>copy-transition-model --binary=false exp/tri4b_ali/final.mdl exp/tri4b_dnn/final.mdl <br>LOG (copy-transition-model[5.5.1050~1-0fb50]:main():copy-transition-model.cc:62) Copied transition model.<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">PREPARING FEATURES</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">+ <span class="hljs-string">&#x27;apply-cmvn&#x27;</span> with <span class="hljs-string">&#x27;--norm-means=true --norm-vars=false&#x27;</span> using statistics : data/fbank/train/cmvn.scp, data/fbank/dev/cmvn.scp</span><br>feat-to-dim &#x27;ark:copy-feats scp:exp/tri4b_dnn/train.scp.10k ark:- | apply-cmvn --norm-means=true --norm-vars=false --utt2spk=ark:data/fbank/train/utt2spk scp:data/fbank/train/cmvn.scp ark:- ark:- |&#x27; - <br>copy-feats scp:exp/tri4b_dnn/train.scp.10k ark:- <br>apply-cmvn --norm-means=true --norm-vars=false --utt2spk=ark:data/fbank/train/utt2spk scp:data/fbank/train/cmvn.scp ark:- ark:- <br>WARNING (feat-to-dim[5.5.1050~1-0fb50]:Close():kaldi-io.cc:515) Pipe copy-feats scp:exp/tri4b_dnn/train.scp.10k ark:- | apply-cmvn --norm-means=true --norm-vars=false --utt2spk=ark:data/fbank/train/utt2spk scp:data/fbank/train/cmvn.scp ark:- ark:- | had nonzero return status 36096<br><span class="hljs-meta prompt_"># </span><span class="language-bash">feature dim : 40 (input of <span class="hljs-string">&#x27;feature_transform&#x27;</span>)</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">+ default <span class="hljs-string">&#x27;feature_transform_proto&#x27;</span> with splice +/-5 frames,</span><br>nnet-initialize --binary=false exp/tri4b_dnn/splice5.proto exp/tri4b_dnn/tr_splice5.nnet <br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;Splice&gt; &lt;InputDim&gt; 40 &lt;OutputDim&gt; 440 &lt;BuildVector&gt; -5:5 &lt;/BuildVector&gt;<br>LOG (nnet-initialize[5.5.1050~1-0fb50]:main():nnet-initialize.cc:63) Written initialized model to exp/tri4b_dnn/tr_splice5.nnet<br><span class="hljs-meta prompt_"># </span><span class="language-bash">feature <span class="hljs-built_in">type</span> : plain</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">compute normalization stats from 10k sentences</span><br>compute-cmvn-stats ark:- exp/tri4b_dnn/cmvn-g.stats <br>nnet-forward --print-args=true --use-gpu=yes exp/tri4b_dnn/tr_splice5.nnet &#x27;ark:copy-feats scp:exp/tri4b_dnn/train.scp.10k ark:- | apply-cmvn --norm-means=true --norm-vars=false --utt2spk=ark:data/fbank/train/utt2spk scp:data/fbank/train/cmvn.scp ark:- ark:- |&#x27; ark:- <br>WARNING (nnet-forward[5.5.1050~1-0fb50]:SelectGpuId():cu-device.cc:243) Not in compute-exclusive mode.  Suggestion: use &#x27;nvidia-smi -c 3&#x27; to set compute exclusive mode<br>LOG (nnet-forward[5.5.1050~1-0fb50]:SelectGpuIdAuto():cu-device.cc:438) Selecting from 1 GPUs<br>LOG (nnet-forward[5.5.1050~1-0fb50]:SelectGpuIdAuto():cu-device.cc:453) cudaSetDevice(0): NVIDIA GeForce GTX 1050	free:3992M, used:47M, total:4040M, free/total:0.98815<br>LOG (nnet-forward[5.5.1050~1-0fb50]:SelectGpuIdAuto():cu-device.cc:501) Device: 0, mem_ratio: 0.98815<br>LOG (nnet-forward[5.5.1050~1-0fb50]:SelectGpuId():cu-device.cc:382) Trying to select device: 0<br>LOG (nnet-forward[5.5.1050~1-0fb50]:SelectGpuIdAuto():cu-device.cc:511) Success selecting device 0 free mem ratio: 0.98815<br>LOG (nnet-forward[5.5.1050~1-0fb50]:FinalizeActiveGpu():cu-device.cc:338) The active GPU is [0]: NVIDIA GeForce GTX 1050	free:3788M, used:251M, total:4040M, free/total:0.937657 version 6.1<br>copy-feats scp:exp/tri4b_dnn/train.scp.10k ark:- <br>apply-cmvn --norm-means=true --norm-vars=false --utt2spk=ark:data/fbank/train/utt2spk scp:data/fbank/train/cmvn.scp ark:- ark:- <br>LOG (copy-feats[5.5.1050~1-0fb50]:main():copy-feats.cc:143) Copied 10000 feature matrices.<br>LOG (apply-cmvn[5.5.1050~1-0fb50]:main():apply-cmvn.cc:162) Applied cepstral mean normalization to 10000 utterances, errors on 0<br>LOG (nnet-forward[5.5.1050~1-0fb50]:main():nnet-forward.cc:192) Done 10000 files in 0.841963min, (fps 181658)<br>LOG (compute-cmvn-stats[5.5.1050~1-0fb50]:main():compute-cmvn-stats.cc:168) Wrote global CMVN stats to exp/tri4b_dnn/cmvn-g.stats<br>LOG (compute-cmvn-stats[5.5.1050~1-0fb50]:main():compute-cmvn-stats.cc:171) Done accumulating CMVN stats for 10000 utterances; 0 had errors.<br><span class="hljs-meta prompt_"># </span><span class="language-bash">+ normalization of NN-input at <span class="hljs-string">&#x27;exp/tri4b_dnn/tr_splice5_cmvn-g.nnet&#x27;</span></span><br>nnet-concat --binary=false exp/tri4b_dnn/tr_splice5.nnet &#x27;cmvn-to-nnet --std-dev=1.0 exp/tri4b_dnn/cmvn-g.stats -|&#x27; exp/tri4b_dnn/tr_splice5_cmvn-g.nnet <br>LOG (nnet-concat[5.5.1050~1-0fb50]:main():nnet-concat.cc:53) Reading exp/tri4b_dnn/tr_splice5.nnet<br>LOG (nnet-concat[5.5.1050~1-0fb50]:main():nnet-concat.cc:65) Concatenating cmvn-to-nnet --std-dev=1.0 exp/tri4b_dnn/cmvn-g.stats -|<br>cmvn-to-nnet --std-dev=1.0 exp/tri4b_dnn/cmvn-g.stats - <br>LOG (cmvn-to-nnet[5.5.1050~1-0fb50]:main():cmvn-to-nnet.cc:114) Written cmvn in &#x27;nnet1&#x27; model to: -<br>LOG (nnet-concat[5.5.1050~1-0fb50]:main():nnet-concat.cc:82) Written model to exp/tri4b_dnn/tr_splice5_cmvn-g.nnet<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">## Showing the final &#x27;feature_transform&#x27;:</span></span><br>nnet-info exp/tri4b_dnn/tr_splice5_cmvn-g.nnet <br>num-components 3<br>input-dim 40<br>output-dim 440<br>number-of-parameters 0.00088 millions<br>component 1 : &lt;Splice&gt;, input-dim 40, output-dim 440, <br>  frame_offsets [ -5 -4 -3 -2 -1 0 1 2 3 4 5 ]<br>component 2 : &lt;AddShift&gt;, input-dim 440, output-dim 440, <br>  shift_data ( min -0.00404477, max 0.0024458, mean -0.000288983, stddev 0.000940905, skewness -0.818492, kurtosis 1.721 ) , lr-coef 0<br>component 3 : &lt;Rescale&gt;, input-dim 440, output-dim 440, <br>  scale_data ( min 0.236916, max 0.392197, mean 0.289203, stddev 0.0389445, skewness 0.623488, kurtosis -0.290958 ) , lr-coef 0<br>LOG (nnet-info[5.5.1050~1-0fb50]:main():nnet-info.cc:57) Printed info about exp/tri4b_dnn/tr_splice5_cmvn-g.nnet<br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">##</span></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">NN-INITIALIZATION</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">getting input/output dims :</span><br>feat-to-dim &#x27;ark:copy-feats scp:exp/tri4b_dnn/train.scp.10k ark:- | apply-cmvn --norm-means=true --norm-vars=false --utt2spk=ark:data/fbank/train/utt2spk scp:data/fbank/train/cmvn.scp ark:- ark:- | nnet-forward &quot;exp/tri4b_dnn/final.feature_transform&quot; ark:- ark:- |&#x27; - <br>copy-feats scp:exp/tri4b_dnn/train.scp.10k ark:- <br>apply-cmvn --norm-means=true --norm-vars=false --utt2spk=ark:data/fbank/train/utt2spk scp:data/fbank/train/cmvn.scp ark:- ark:- <br>nnet-forward exp/tri4b_dnn/final.feature_transform ark:- ark:- <br>LOG (nnet-forward[5.5.1050~1-0fb50]:SelectGpuId():cu-device.cc:168) Manually selected to compute on CPU.<br>WARNING (feat-to-dim[5.5.1050~1-0fb50]:Close():kaldi-io.cc:515) Pipe copy-feats scp:exp/tri4b_dnn/train.scp.10k ark:- | apply-cmvn --norm-means=true --norm-vars=false --utt2spk=ark:data/fbank/train/utt2spk scp:data/fbank/train/cmvn.scp ark:- ark:- | nnet-forward &quot;exp/tri4b_dnn/final.feature_transform&quot; ark:- ark:- | had nonzero return status 36096<br><span class="hljs-meta prompt_"># </span><span class="language-bash">genrating network prototype exp/tri4b_dnn/nnet.proto</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">initializing the NN <span class="hljs-string">&#x27;exp/tri4b_dnn/nnet.proto&#x27;</span> -&gt; <span class="hljs-string">&#x27;exp/tri4b_dnn/nnet.init&#x27;</span></span><br>nnet-initialize --seed=777 exp/tri4b_dnn/nnet.proto exp/tri4b_dnn/nnet.init <br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;AffineTransform&gt; &lt;InputDim&gt; 440 &lt;OutputDim&gt; 1024 &lt;BiasMean&gt; -2.000000 &lt;BiasRange&gt; 4.000000 &lt;ParamStddev&gt; 0.037344 &lt;MaxNorm&gt; 0.000000 <br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;Sigmoid&gt; &lt;InputDim&gt; 1024 &lt;OutputDim&gt; 1024 <br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;AffineTransform&gt; &lt;InputDim&gt; 1024 &lt;OutputDim&gt; 1024 &lt;BiasMean&gt; -2.000000 &lt;BiasRange&gt; 4.000000 &lt;ParamStddev&gt; 0.109375 &lt;MaxNorm&gt; 0.000000 <br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;Sigmoid&gt; &lt;InputDim&gt; 1024 &lt;OutputDim&gt; 1024 <br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;AffineTransform&gt; &lt;InputDim&gt; 1024 &lt;OutputDim&gt; 1024 &lt;BiasMean&gt; -2.000000 &lt;BiasRange&gt; 4.000000 &lt;ParamStddev&gt; 0.109375 &lt;MaxNorm&gt; 0.000000 <br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;Sigmoid&gt; &lt;InputDim&gt; 1024 &lt;OutputDim&gt; 1024 <br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;AffineTransform&gt; &lt;InputDim&gt; 1024 &lt;OutputDim&gt; 1024 &lt;BiasMean&gt; -2.000000 &lt;BiasRange&gt; 4.000000 &lt;ParamStddev&gt; 0.109375 &lt;MaxNorm&gt; 0.000000 <br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;Sigmoid&gt; &lt;InputDim&gt; 1024 &lt;OutputDim&gt; 1024 <br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;AffineTransform&gt; &lt;InputDim&gt; 1024 &lt;OutputDim&gt; 3392 &lt;BiasMean&gt; 0.000000 &lt;BiasRange&gt; 0.000000 &lt;ParamStddev&gt; 0.074485 &lt;LearnRateCoef&gt; 1.000000 &lt;BiasLearnRateCoef&gt; 0.100000<br>VLOG[1] (nnet-initialize[5.5.1050~1-0fb50]:Init():nnet-nnet.cc:314) &lt;Softmax&gt; &lt;InputDim&gt; 3392 &lt;OutputDim&gt; 3392<br>LOG (nnet-initialize[5.5.1050~1-0fb50]:main():nnet-initialize.cc:63) Written initialized model to exp/tri4b_dnn/nnet.init<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">RUNNING THE NN-TRAINING SCHEDULER</span><br>steps/nnet/train_scheduler.sh --feature-transform exp/tri4b_dnn/final.feature_transform --learn-rate 0.008 exp/tri4b_dnn/nnet.init ark:copy-feats scp:exp/tri4b_dnn/train.scp ark:- | apply-cmvn --norm-means=true --norm-vars=false --utt2spk=ark:data/fbank/train/utt2spk scp:data/fbank/train/cmvn.scp ark:- ark:- | ark:copy-feats scp:exp/tri4b_dnn/cv.scp ark:- | apply-cmvn --norm-means=true --norm-vars=false --utt2spk=ark:data/fbank/dev/utt2spk scp:data/fbank/dev/cmvn.scp ark:- ark:- | ark:ali-to-pdf exp/tri4b_ali/final.mdl &quot;ark:gunzip -c exp/tri4b_ali/ali.*.gz |&quot; ark:- | ali-to-post ark:- ark:- | ark:ali-to-pdf exp/tri4b_ali/final.mdl &quot;ark:gunzip -c exp/tri4b_ali_cv/ali.*.gz |&quot; ark:- | ali-to-post ark:- ark:- | exp/tri4b_dnn<br>CROSSVAL PRERUN AVG.LOSS 8.4100 (Xent),<br>ITERATION 01: TRAIN AVG.LOSS 2.0844, (lrate0.008), CROSSVAL AVG.LOSS 2.2329, nnet accepted (nnet_iter01_learnrate0.008_tr2.0844_cv2.2329)<br>ITERATION 02: TRAIN AVG.LOSS 1.4095, (lrate0.008), CROSSVAL AVG.LOSS 2.0038, nnet accepted (nnet_iter02_learnrate0.008_tr1.4095_cv2.0038)<br>ITERATION 03: TRAIN AVG.LOSS 1.2454, (lrate0.008), CROSSVAL AVG.LOSS 1.9345, nnet accepted (nnet_iter03_learnrate0.008_tr1.2454_cv1.9345)<br>ITERATION 04: steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/mono/graph_word exp/mono/decode_test_word<br>steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_test_word/log/analyze_alignments.log<br>Overall, lattice depth (10,50,90-percentile)=(3,36,179) and mean=70.2<br>steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_test_word/log/analyze_lattice_depth_stats.log<br>local/score.sh --cmd run.pl --mem 4G data/mfcc/test exp/mono/graph_word exp/mono/decode_test_word<br>local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0<br>Traceback (most recent call last):<br>  File &quot;local/wer_output_filter&quot;, line 15, in &lt;module&gt;<br>    v = v.encode(&#x27;utf-8&#x27;).decode(&#x27;utf-8&#x27;)<br>UnicodeDecodeError: &#x27;ascii&#x27; codec can&#x27;t decode byte 0xe4 in position 0: ordinal not in range(128)<br>steps/decode.sh: Error: scoring failed. (ignore by &#x27;--skip-scoring true&#x27;)<br>TRAIN AVG.LOSS 1.1448, (lrate0.008), CROSSVAL AVG.LOSS 1.9161, nnet accepted (nnet_iter04_learnrate0.008_tr1.1448_cv1.9161)<br>ITERATION 05: TRAIN AVG.LOSS 1.0634, (lrate0.004), CROSSVAL AVG.LOSS 1.7115, nnet accepted (nnet_iter05_learnrate0.004_tr1.0634_cv1.7115)<br>ITERATION 06: TRAIN AVG.LOSS 1.0256, (lrate0.002), CROSSVAL AVG.LOSS 1.5842, nnet accepted (nnet_iter06_learnrate0.002_tr1.0256_cv1.5842)<br>ITERATION 07: TRAIN AVG.LOSS 1.0191, (lrate0.001), CROSSVAL AVG.LOSS 1.5023, nnet accepted (nnet_iter07_learnrate0.001_tr1.0191_cv1.5023)<br>ITERATION 08: TRAIN AVG.LOSS 1.0233, (lrate0.0005), CROSSVAL AVG.LOSS 1.4487, nnet accepted (nnet_iter08_learnrate0.0005_tr1.0233_cv1.4487)<br>ITERATION 09: TRAIN AVG.LOSS 1.0284, (lrate0.00025), CROSSVAL AVG.LOSS 1.4156, nnet accepted (nnet_iter09_learnrate0.00025_tr1.0284_cv1.4156)<br>ITERATION 10: TRAIN AVG.LOSS 1.0315, (lrate0.000125), CROSSVAL AVG.LOSS 1.3976, nnet accepted (nnet_iter10_learnrate0.000125_tr1.0315_cv1.3976)<br>ITERATION 11: TRAIN AVG.LOSS 1.0327, (lrate6.25e-05), CROSSVAL AVG.LOSS 1.3882, nnet accepted (nnet_iter11_learnrate6.25e-05_tr1.0327_cv1.3882)<br>ITERATION 12: TRAIN AVG.LOSS 1.0327, (lrate3.125e-05), CROSSVAL AVG.LOSS 1.3837, nnet accepted (nnet_iter12_learnrate3.125e-05_tr1.0327_cv1.3837)<br>ITERATION 13: TRAIN AVG.LOSS 1.0323, (lrate1.5625e-05), CROSSVAL AVG.LOSS 1.3816, nnet accepted (nnet_iter13_learnrate1.5625e-05_tr1.0323_cv1.3816)<br>ITERATION 14: TRAIN AVG.LOSS 1.0318, (lrate7.8125e-06), CROSSVAL AVG.LOSS 1.3806, nnet accepted (nnet_iter14_learnrate7.8125e-06_tr1.0318_cv1.3806)<br>finished, too small rel. improvement 0.000752729<br>steps/nnet/train_scheduler.sh: Succeeded training the Neural Network : &#x27;exp/tri4b_dnn/final.nnet&#x27;<br>steps/nnet/train.sh: Successfuly finished. &#x27;exp/tri4b_dnn&#x27;<br>steps/nnet/decode.sh --nj 8 --cmd run.pl --mem 4G --srcdir exp/tri4b_dnn --config conf/decode_dnn.config --acwt 0.1 exp/tri4b/graph_phone data/fbank/test_phone exp/tri4b_dnn/decode_test_phone<br>steps/nnet/align.sh --nj 8 --cmd run.pl data/fbank/train data/lang exp/tri4b_dnn exp/tri4b_dnn_ali<br>steps/nnet/decode.sh --nj 8 --cmd run.pl --mem 4G --srcdir exp/tri4b_dnn --config conf/decode_dnn.config --acwt 0.1 exp/tri4b/graph_word data/fbank/test exp/tri4b_dnn/decode_test_word<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_phone/HCLG.fst<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_word/HCLG.fst<br>steps/nnet/align.sh: aligning data &#x27;data/fbank/train&#x27; using nnet/model &#x27;exp/tri4b_dnn&#x27;, putting alignments in &#x27;exp/tri4b_dnn_ali&#x27;<br><span class="hljs-meta prompt_"># </span><span class="language-bash">Accounting: time=6894 threads=1</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">Ended (code 0) at Wed Aug 31 19:45:14 CST 2022, elapsed time 6894 seconds</span><br>steps/nnet/align.sh: done aligning data.<br>steps/nnet/make_denlats.sh --nj 8 --cmd run.pl --mem 4G --config conf/decode_dnn.config --acwt 0.1 data/fbank/train data/lang exp/tri4b_dnn exp/tri4b_dnn_denlats<br>Making unigram grammar FST in exp/tri4b_dnn_denlats/lang<br>sym2int.pl: replacing l with 2<br>sym2int.pl: replacing = with 2<br>sym2int.pl: replacing l with 2<br>sym2int.pl: replacing = with 2<br>sym2int.pl: replacing l with 2<br>sym2int.pl: replacing = with 2<br>sym2int.pl: replacing l with 2<br>sym2int.pl: replacing = with 2<br>sym2int.pl: replacing l with 2<br>sym2int.pl: replacing = with 2<br>sym2int.pl: replacing l with 2<br>sym2int.pl: replacing = with 2<br>sym2int.pl: replacing l with 2<br>sym2int.pl: replacing = with 2<br>sym2int.pl: replacing l with 2<br>sym2int.pl: replacing = with 2<br>sym2int.pl: replacing l with 2<br>sym2int.pl: replacing = with 2<br>sym2int.pl: replacing l with 2<br>sym2int.pl: replacing = with 2<br>sym2int.pl: not warning for OOVs any more times<br>** Replaced 22 instances of OOVs with 2<br>Compiling decoding graph in exp/tri4b_dnn_denlats/dengraph<br>tree-info exp/tri4b_dnn/tree <br>tree-info exp/tri4b_dnn/tree <br>fstpushspecial <br>fstminimizeencoded <br>fstdeterminizestar --use-log=true <br>fsttablecompose exp/tri4b_dnn_denlats/lang/L_disambig.fst exp/tri4b_dnn_denlats/lang/G.fst <br>fstisstochastic exp/tri4b_dnn_denlats/lang/tmp/LG.fst <br>-0.0323879 -0.0325606<br>[info]: LG not stochastic.<br>fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=exp/tri4b_dnn_denlats/lang/phones/disambig.int --write-disambig-syms=exp/tri4b_dnn_denlats/lang/tmp/disambig_ilabels_3_1.int exp/tri4b_dnn_denlats/lang/tmp/ilabels_3_1.541227 exp/tri4b_dnn_denlats/lang/tmp/LG.fst <br>fstisstochastic exp/tri4b_dnn_denlats/lang/tmp/CLG_3_1.fst <br>0 -0.0325606<br>[info]: CLG not stochastic.<br>make-h-transducer --disambig-syms-out=exp/tri4b_dnn_denlats/dengraph/disambig_tid.int --transition-scale=1.0 exp/tri4b_dnn_denlats/lang/tmp/ilabels_3_1 exp/tri4b_dnn/tree exp/tri4b_dnn/final.mdl <br>fsttablecompose exp/tri4b_dnn_denlats/dengraph/Ha.fst exp/tri4b_dnn_denlats/lang/tmp/CLG_3_1.fst <br>fstminimizeencoded <br>fstdeterminizestar --use-log=true <br>fstrmepslocal <br>fstrmsymbols exp/tri4b_dnn_denlats/dengraph/disambig_tid.int <br>fstisstochastic exp/tri4b_dnn_denlats/dengraph/HCLGa.fst <br>0.661133 -0.0799874<br>HCLGa is not stochastic<br>add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri4b_dnn/final.mdl exp/tri4b_dnn_denlats/dengraph/HCLGa.fst <br>steps/nnet/make_denlats.sh: generating denlats from data &#x27;data/fbank/train&#x27;, putting lattices in &#x27;exp/tri4b_dnn_denlats&#x27;<br>steps/nnet/make_denlats.sh: done generating denominator lattices.<br>steps/nnet/train_mpe.sh --cmd run.pl --gpu 1 --num-iters 3 --acwt 0.1 --do-smbr false data/fbank/train data/lang exp/tri4b_dnn exp/tri4b_dnn_ali exp/tri4b_dnn_denlats exp/tri4b_dnn_mpe<br>Pass 1 (learnrate 0.00001)<br> TRAINING FINISHED; Time taken = 6.98081 min; processed 21905.1 frames per second.<br> Done 9998 files, 2 with no reference alignments, 0 with no lattices, 0 with other errors.<br> Overall average frame-accuracy is 0.977291 over 9174910 frames.<br>Pass 2 (learnrate 1e-05)<br> TRAINING FINISHED; Time taken = 7.42708 min; processed 20588.9 frames per second.<br> Done 9998 files, 2 with no reference alignments, 0 with no lattices, 0 with other errors.<br> Overall average frame-accuracy is 0.978551 over 9174910 frames.<br>Pass 3 (learnrate 1e-05)<br> TRAINING FINISHED; Time taken = 7.18205 min; processed 21291.3 frames per second.<br> Done 9998 files, 2 with no reference alignments, 0 with no lattices, 0 with other errors.<br> Overall average frame-accuracy is 0.979353 over 9174910 frames.<br>MPE/sMBR training finished<br>Re-estimating priors by forwarding 10k utterances from training set.<br>steps/nnet/make_priors.sh --cmd run.pl --nj 8 data/fbank/train exp/tri4b_dnn_mpe<br>Accumulating prior stats by forwarding &#x27;data/fbank/train&#x27; with &#x27;exp/tri4b_dnn_mpe&#x27;<br>Succeeded creating prior counts &#x27;exp/tri4b_dnn_mpe/prior_counts&#x27; from &#x27;data/fbank/train&#x27;<br>steps/nnet/train_mpe.sh: Done. &#x27;exp/tri4b_dnn_mpe&#x27;<br>steps/nnet/decode.sh --nj 8 --cmd run.pl --mem 4G --nnet exp/tri4b_dnn_mpe/3.nnet --config conf/decode_dnn.config --acwt 0.1 exp/tri4b/graph_phone data/fbank/test_phone exp/tri4b_dnn_mpe/decode_test_phone_it3<br>steps/nnet/decode.sh --nj 8 --cmd run.pl --mem 4G --nnet exp/tri4b_dnn_mpe/2.nnet --config conf/decode_dnn.config --acwt 0.1 exp/tri4b/graph_phone data/fbank/test_phone exp/tri4b_dnn_mpe/decode_test_phone_it2<br>steps/nnet/decode.sh --nj 8 --cmd run.pl --mem 4G --nnet exp/tri4b_dnn_mpe/2.nnet --config conf/decode_dnn.config --acwt 0.1 exp/tri4b/graph_word data/fbank/test exp/tri4b_dnn_mpe/decode_test_word_it2<br>steps/nnet/decode.sh --nj 8 --cmd run.pl --mem 4G --nnet exp/tri4b_dnn_mpe/1.nnet --config conf/decode_dnn.config --acwt 0.1 exp/tri4b/graph_word data/fbank/test exp/tri4b_dnn_mpe/decode_test_word_it1<br>steps/nnet/decode.sh --nj 8 --cmd run.pl --mem 4G --nnet exp/tri4b_dnn_mpe/1.nnet --config conf/decode_dnn.config --acwt 0.1 exp/tri4b/graph_phone data/fbank/test_phone exp/tri4b_dnn_mpe/decode_test_phone_it1<br>steps/nnet/decode.sh --nj 8 --cmd run.pl --mem 4G --nnet exp/tri4b_dnn_mpe/3.nnet --config conf/decode_dnn.config --acwt 0.1 exp/tri4b/graph_word data/fbank/test exp/tri4b_dnn_mpe/decode_test_word_it3<br>DAE: switching to per-utterance CMVN mode<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_phone/HCLG.fst<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_phone/HCLG.fst<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_word/HCLG.fst<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_word/HCLG.fst<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_word/HCLG.fst<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_phone/HCLG.fst<br>steps/compute_cmvn_stats.sh data/fbank/train exp/fbank_cmvn/train.per_utt fbank/per_utt<br>Succeeded creating CMVN stats for train<br>steps/compute_cmvn_stats.sh data/fbank/dev exp/fbank_cmvn/dev.per_utt fbank/per_utt<br>Succeeded creating CMVN stats for dev<br>steps/compute_cmvn_stats.sh data/fbank/test exp/fbank_cmvn/test.per_utt fbank/per_utt<br>Succeeded creating CMVN stats for test<br>steps/compute_cmvn_stats.sh data/fbank/test_phone exp/fbank_cmvn/test_phone.per_utt fbank/per_utt<br>Succeeded creating CMVN stats for test_phone<br>DAE: generate training data...<br>steps/make_fbank.sh --nj 8 --cmd run.pl data/dae/train exp/dae/gendata fbank/dae/train<br>utils/validate_data_dir.sh: Successfully validated data-directory data/dae/train<br>steps/make_fbank.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>steps/make_fbank.sh: Succeeded creating filterbank features for train<br>steps/compute_cmvn_stats.sh data/dae/train exp/dae/cmvn fbank/dae/train<br>Succeeded creating CMVN stats for train<br>DAE: generating dev data...<br>steps/make_fbank.sh --nj 8 --cmd run.pl data/dae/dev/0db exp/dae/gendata fbank/dae/dev/0db<br>utils/validate_data_dir.sh: Successfully validated data-directory data/dae/dev/0db<br>steps/make_fbank.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>steps/make_fbank.sh: Succeeded creating filterbank features for 0db<br>steps/compute_cmvn_stats.sh data/dae/dev/0db exp/dae/cmvn fbank/dae/dev/0db<br>Succeeded creating CMVN stats for 0db<br>DAE: generating test data...<br>producing fbanks for car<br>steps/make_fbank.sh --nj 8 --cmd run.pl data/dae/test/0db/car exp/dae/gendata fbank/dae/test/0db/car<br>utils/validate_data_dir.sh: Successfully validated data-directory data/dae/test/0db/car<br>steps/make_fbank.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>steps/make_fbank.sh: Succeeded creating filterbank features for car<br>generating cmvn for test data car<br>steps/compute_cmvn_stats.sh data/dae/test/0db/car exp/dae/cmvn fbank/dae/test/0db/car<br>Succeeded creating CMVN stats for car<br>producing fbanks for white<br>steps/make_fbank.sh --nj 8 --cmd run.pl data/dae/test/0db/white exp/dae/gendata fbank/dae/test/0db/white<br>utils/validate_data_dir.sh: Successfully validated data-directory data/dae/test/0db/white<br>steps/make_fbank.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>steps/make_fbank.sh: Succeeded creating filterbank features for white<br>generating cmvn for test data white<br>steps/compute_cmvn_stats.sh data/dae/test/0db/white exp/dae/cmvn fbank/dae/test/0db/white<br>Succeeded creating CMVN stats for white<br>producing fbanks for cafe<br>steps/make_fbank.sh --nj 8 --cmd run.pl data/dae/test/0db/cafe exp/dae/gendata fbank/dae/test/0db/cafe<br>utils/validate_data_dir.sh: Successfully validated data-directory data/dae/test/0db/cafe<br>steps/make_fbank.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>steps/make_fbank.sh: Succeeded creating filterbank features for cafe<br>generating cmvn for test data cafe<br>steps/compute_cmvn_stats.sh data/dae/test/0db/cafe exp/dae/cmvn fbank/dae/test/0db/cafe<br>Succeeded creating CMVN stats for cafe<br>feat-to-dim scp:exp/tri4b_dnn_dae/tgt_feats.scp - <br>num_fea = 40<br>nnet-concat exp/tri4b_dnn_dae/final.feature_transform exp/tri4b_dnn_dae/final.nnet exp/tri4b_dnn_mpe/final.feature_transform exp/tri4b_dnn_dae/dae.nnet <br>LOG (nnet-concat[5.5.1050~1-0fb50]:main():nnet-concat.cc:53) Reading exp/tri4b_dnn_dae/final.feature_transform<br>LOG (nnet-concat[5.5.1050~1-0fb50]:main():nnet-concat.cc:65) Concatenating exp/tri4b_dnn_dae/final.nnet<br>LOG (nnet-concat[5.5.1050~1-0fb50]:main():nnet-concat.cc:65) Concatenating exp/tri4b_dnn_mpe/final.feature_transform<br>LOG (nnet-concat[5.5.1050~1-0fb50]:main():nnet-concat.cc:82) Written model to exp/tri4b_dnn_dae/dae.nnet<br>DAE: switch bach to per-speaker CMVN mode<br>steps/nnet/decode.sh --cmd run.pl --mem 4G --nj 8 --srcdir exp/tri4b_dnn_mpe exp/tri4b/graph_word data/dae/test/0db/car exp/tri4b_dnn_mpe/decode_word_0db/car<br>steps/nnet/decode.sh --cmd run.pl --mem 4G --nj 8 --srcdir exp/tri4b_dnn_mpe exp/tri4b/graph_word data/dae/test/0db/white exp/tri4b_dnn_mpe/decode_word_0db/white<br>steps/nnet/decode.sh --cmd run.pl --mem 4G --nj 8 --srcdir exp/tri4b_dnn_mpe exp/tri4b/graph_word data/dae/test/0db/cafe exp/tri4b_dnn_mpe/decode_word_0db/cafe<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_word/HCLG.fst<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_word/HCLG.fst<br>steps/nnet/decode.sh: missing file exp/tri4b/graph_word/HCLG.fst<br><br></code></pre></td></tr></table></figure>

<h3 id="dnn模型训练"><a href="#dnn模型训练" class="headerlink" title="dnn模型训练"></a>dnn模型训练</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">train dnn model</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">dnn模型训练，采用DNN来训练一个声学模型</span><br>local/nnet/run_dnn.sh --stage 0 --nj $n  exp/tri4b exp/tri4b_ali exp/tri4b_ali_cv || exit 1;<br></code></pre></td></tr></table></figure>

<h3 id="dae模型训练"><a href="#dae模型训练" class="headerlink" title="dae模型训练"></a>dae模型训练</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">train dae model</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">dae模型训练，通过对语音数据添加噪声来得到有噪音的数据，而后调用nnet1/train_dnn.sh来对其进行训练，训练细节和dnn部分一样</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">python2.6 or above is required <span class="hljs-keyword">for</span> noisy data generation.</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">To speed up the process, pyximport <span class="hljs-keyword">for</span> python is recommeded.</span><br>local/dae/run_dae.sh $thchs || exit 1;<br></code></pre></td></tr></table></figure>

<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>执行run.sh的时候,要先执行cmd.sh和path.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">cmd.sh</span><br>export train_cmd=&quot;queue.pl -q wolf.cpu.q&quot;<br>export decode_cmd=&quot;queue.pl -q wolf.cpu.q&quot;<br>export cuda_cmd=&quot;queue.pl -q wolf.gpu.q&quot;<br></code></pre></td></tr></table></figure>

<p>运行环境，不同的并行处理方案要调用不同的脚本</p>
<p>我们首先需要配置是在单机还是在Oracle GridEngine集群上训练，这可以通过cmd.sh来配置。如果我们没有GridEngine(通常没有)，那么需要把所有的queue.pl改成run.pl。（GPU CPU参与）</p>
<blockquote>
<p>queue.ql: GridEngine多机运行，一种多cpu（gpu）的并行处理方案。</p>
<p>run.ql: 本地多进程。</p>
</blockquote>
<p>e.g.如果出问题把queue,pl换成run.pl</p>
<p><img src="https://picture-store-repository.oss-cn-hangzhou.aliyuncs.com/blog/image-20220901082724279.png" srcset="/img/loading.gif" lazyload alt="image-20220901082724279"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">steps/make_mfcc.sh --nj 8 --cmd queue.pl data/mfcc/train exp/make_mfcc/train mfcc/train<br>utils/validate_data_dir.sh: Successfully validated data-directory data/mfcc/train<br>steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.<br>queue.pl: Error submitting jobs to queue (return status was 32512)<br>queue log file is exp/make_mfcc/train/q/make_mfcc_train.log, command was qsub -v PATH -cwd -S /bin/bash -j y -l arch=*64* -o exp/make_mfcc/train/q/make_mfcc_train.log   -t 1:8 /home/baixf/kaldi/egs/thchs30/s5/exp/make_mfcc/train/q/make_mfcc_train.sh &gt;&gt;exp/make_mfcc/train/q/make_mfcc_train.log 2&gt;&amp;1<br>Output of qsub was: sh: 1: qsub: not found<br></code></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42734492/article/details/112385262">AIBigKaldi（十）| Kaldi的thchs30实例（源码解析）</a>
<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42734492/article/details/112548161">AIBigKaldi（十一）| Kaldi的三音素模型训练（上）（源码解析）</a>
<a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a target="_blank" rel="noopener" href="http://pelhans.com/tags/#Kaldi">Kaldi thchs30手札</a>
<a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/210975288">语音识别系列之高阶解码器技术</a>
<a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:5" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/095939c4617f">WFST 语言模型</a>
<a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:6" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://blog.csdn.net/KanShiMeKan/article/details/71250135">Kaldi学习笔记（二）</a>
<a href="#fnref:6" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%AD%A6%E4%B9%A0/" class="category-chain-item">学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E5%AD%A6%E4%B9%A0/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/" class="category-chain-item">语音识别</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/">#语音识别</a>
      
        <a href="/tags/ASR/">#ASR</a>
      
        <a href="/tags/kaldi/">#kaldi</a>
      
        <a href="/tags/%E5%8D%95%E9%9F%B3%E7%B4%A0/">#单音素</a>
      
        <a href="/tags/%E4%B8%89%E9%9F%B3%E7%B4%A0/">#三音素</a>
      
        <a href="/tags/%E7%8A%B6%E6%80%81%E7%BB%91%E5%AE%9A/">#状态绑定</a>
      
        <a href="/tags/thchs30/">#thchs30</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Class6 作业-Kaldi的thchs30实例</div>
      <div>https://blog.baixf.shop/2022/08/31/语音识别学习/Class6 作业-Kaldi的thchs30实例/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>白小飞</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年8月31日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>

<div style="width:100%;display:flex;justify-content:center;margin-bottom:1.5rem"><ins class="adsbygoogle" style="display:flex;justify-content:center;max-width:845px;width:100%;height:90px" data-ad-client="ca-pub-8876055955767828" data-ad-slot="9285507003"></ins><script> (adsbygoogle = window.adsbygoogle || []).push({}); </script></div>

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/09/01/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%AD%A6%E4%B9%A0/Class7%20LM%E4%BD%9C%E4%B8%9A-%E5%9F%BA%E4%BA%8Esrilm%E7%9A%84%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/" title="Class7 LM作业-基于srilm的语言模型训练">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Class7 LM作业-基于srilm的语言模型训练</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/08/30/Data%20Structure/Q4-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="Q4-数据结构">
                        <span class="hidden-mobile">Q4-数据结构</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <div> <span id="timeDate">载入天数...</span> <span id="times">载入时分秒...</span> <script src="/js/duration.js"></script> </div> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
    <!-- cnzz Analytics Icon -->
    <span id="cnzz_stat_icon_1279684341" style="display: none"></span>
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  
<script src="/js/click.js"></script>
<script src="/js/bg.js"></script>
<script src="/js/forbid.js"></script>
<script src="/js/cloudflare.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8876055955767828" crossorigin="anonymous"></script>

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
